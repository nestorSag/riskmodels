<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>riskmodels.adequacy.capacity_models API documentation</title>
<meta name="description" content="This module implements power system capacity models for adequacy assessment calculations. There are sequential and non-sequential (also called â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>riskmodels.adequacy.capacity_models</code></h1>
</header>
<section id="section-intro">
<p>This module implements power system capacity models for adequacy assessment calculations. There are sequential and non-sequential (also called time-collapsed) implementations:</p>
<p>In the case of sequential models, because Monte Carlo estimation is the only way to compute statistical properties of time series models for capacity surpluses, these rely heavily on large-scale simulation and computation. The classes of this module implement multi-core processing following a map-reduce pattern on a large number of simulated traces that are persisted in multiple files. The main classes are <code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential" href="#riskmodels.adequacy.capacity_models.UnivariateSequential">UnivariateSequential</a></code> and <code><a title="riskmodels.adequacy.capacity_models.BivariateSequential" href="#riskmodels.adequacy.capacity_models.BivariateSequential">BivariateSequential</a></code>.</p>
<p>In the case of non-sequential or time-collapsed, only two-area models are implemented, as single-area time collapsed models reduce to fairly simple discrete probability distributions and can be handled using the <code>univariate</code> module. The main classes are <code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo">BivariateNSMonteCarlo</a></code> and <code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical">BivariateNSEmpirical</a></code> empirical, the <code>NS</code> standing for non-sequential. The former takes arbitrary bivariate ACG and net demand distributions and computes time-collapsed metrics using Monte Carlo estimation; however, it only implements a <code>veto</code> policy in which capacity can only flow to other areas after domestic demand has been satisfied.</p>
<p>The latter uses a non-sequential ACG model from the <code>acg_models</code> module and takes as net demand model the empirical distribution of historic net demand, passed as arrays of historic wind output and demand. This model computes EEU and LOLE metrics exactly by processing the two-dimensional ACG probability distribution, and also implements a <code>share</code> policy in which shortfalls can be shared in proportion to demand across areas, up to the interconnector capacity. The actual numerical implementation is written in <code>C</code>, to which this class interfaces.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
This module implements power system capacity models for adequacy assessment calculations. There are sequential and non-sequential (also called time-collapsed) implementations:

In the case of sequential models, because Monte Carlo estimation is the only way to compute statistical properties of time series models for capacity surpluses, these rely heavily on large-scale simulation and computation. The classes of this module implement multi-core processing following a map-reduce pattern on a large number of simulated traces that are persisted in multiple files. The main classes are `UnivariateSequential` and `BivariateSequential`.

In the case of non-sequential or time-collapsed, only two-area models are implemented, as single-area time collapsed models reduce to fairly simple discrete probability distributions and can be handled using the `univariate` module. The main classes are `BivariateNSMonteCarlo` and `BivariateNSEmpirical` empirical, the `NS` standing for non-sequential. The former takes arbitrary bivariate ACG and net demand distributions and computes time-collapsed metrics using Monte Carlo estimation; however, it only implements a `veto` policy in which capacity can only flow to other areas after domestic demand has been satisfied.

The latter uses a non-sequential ACG model from the `acg_models` module and takes as net demand model the empirical distribution of historic net demand, passed as arrays of historic wind output and demand. This model computes EEU and LOLE metrics exactly by processing the two-dimensional ACG probability distribution, and also implements a `share` policy in which shortfalls can be shared in proportion to demand across areas, up to the interconnector capacity. The actual numerical implementation is written in `C`, to which this class interfaces.
&#34;&#34;&#34;

from __future__ import annotations
import warnings
from abc import ABC, abstractmethod
from pathlib import Path
import copy
import typing as t
from zlib import adler32
from multiprocessing import Pool

import numpy as np
import pandas as pd
from scipy.optimize import bisect

from pydantic import BaseModel as BasePydanticModel, validator

import riskmodels.univariate as univar
from riskmodels.bivariate import Independent, BaseDistribution
from riskmodels.adequacy import acg_models

from riskmodels.utils.adequacy_interfaces import (
    BaseBivariateMonteCarlo,
    BaseCapacityModel,
)
from riskmodels.utils.map_reduce import UnivariateTraces, BivariateTraces

from tqdm import tqdm

from c_sequential_models_api import ffi, lib as C_CALL
from c_bivariate_surplus_api import ffi, lib as C_API

pd.options.mode.chained_assignment = None  # default=&#39;warn&#39;


class BivariateNSMonteCarlo(BaseBivariateMonteCarlo):

    &#34;&#34;&#34;Non-sequential bivariate capacity surplus model that takes arbitrary bivariate distributions (inheriting from `riskmodels.bivariate.BaseDistribution`) for ACG and net demand. It calculates time-collapsed risk metrics by simulation and only implements a veto policy between areas, this is, areas will only export spare available capacity. For models that implement a `share` policy, see `BivariateSequential` and `BivariateNSEmpirical`.

    Args:
        gen_distribution (BaseDistribution): available conventional generation distribution
        net_demand (BaseDistribution): net demand distribution
        size (int): Sample size for Monte Carlo estimation

    &#34;&#34;&#34;

    gen_distribution: BaseDistribution
    net_demand: BaseDistribution
    size: int

    class Config:
        arbitrary_types_allowed = True

    def get_pre_itc_sample(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Returns a pre-interconnection surplus sample by simulating the passed bivariate distributions for available conventional generation and net demand

        Returns:
            np.ndarray: Sample
        &#34;&#34;&#34;
        return self.gen_distribution.simulate(self.size) - self.net_demand.simulate(
            self.size
        )


class BivariateNSEmpirical(BaseCapacityModel):

    &#34;&#34;&#34;Non-sequential model that uses a hindcast net demand model to compute exact LOLE and EEU risk indices; it implements both `veto` and `share` policies&#34;&#34;&#34;

    def __repr__(self):
        return f&#34;Bivariate empirical surplus model with {len(self.demand_data)} observations&#34;

    def __init__(
        self,
        demand_data: np.ndarray,
        renewables_data: np.ndarray,
        gen_distribution: Independent,
        season_length: int = None,
    ):
        &#34;&#34;&#34;

        Args:
          demand_data (np.ndarray): Demand data matrix with two columns
          gen_distribution (Independent): A bivariate distribution with independent components, where each component is a univar.Binned instance representing the distribution of available conventional generation for the corresponding area
          renewables_data (np.ndarray): Renewable generation data matrix with two columns
          season_length (int, optional): length of peak season. If None, it is set as the length of demand data

        &#34;&#34;&#34;
        warnings.warn(&#34;Coercing data to integer values.&#34;, stacklevel=2)

        self.demand_data = np.ascontiguousarray(demand_data, dtype=np.int32)
        self.renewables_data = np.ascontiguousarray(renewables_data, dtype=np.int32)
        self.net_demand_data = np.ascontiguousarray(
            self.demand_data - self.renewables_data
        )

        if not isinstance(gen_distribution.x, univar.Binned) or not isinstance(
            gen_distribution.y, univar.Binned
        ):
            raise TypeError(
                &#34;Marginal generation distributions must be instances of Binned (i.e. integer support).&#34;
            )

        # save hard copy of relevant arrays from generation
        # this is needed because strange things happened when copying arrays directly from the Independent instance. This somehow solves the issue
        self.convgen1 = {
            &#34;min&#34;: gen_distribution.x.min,
            &#34;max&#34;: gen_distribution.x.max,
            &#34;cdf_values&#34;: np.ascontiguousarray(
                np.copy(gen_distribution.x.cdf_values, order=&#34;C&#34;)
            ),
            &#34;expectation_vals&#34;: np.ascontiguousarray(
                np.cumsum(gen_distribution.x.support * gen_distribution.x.pdf_values)
            ),
        }

        self.convgen2 = {
            &#34;min&#34;: gen_distribution.y.min,
            &#34;max&#34;: gen_distribution.y.max,
            &#34;cdf_values&#34;: np.ascontiguousarray(
                np.copy(gen_distribution.y.cdf_values, order=&#34;C&#34;)
            ),
            &#34;expectation_vals&#34;: np.ascontiguousarray(
                np.cumsum(gen_distribution.y.support * gen_distribution.y.pdf_values)
            ),
        }

        self.gen_distribution = gen_distribution
        self.MARGIN_BOUND = int(np.iinfo(np.int32).max / 2)

        if season_length is None:
            warnings.warn(&#34;Using length of demand data as season length.&#34;, stacklevel=2)
        self.season_length = (
            len(self.demand_data) if season_length is None else season_length
        )

    def cdf(self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;):
        &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

        Args:
            x (np.ndarray): value at which to evaluate the cdf
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

        &#34;&#34;&#34;

        # if x is an n x 2 matrix
        if len(x.shape) == 2 and len(x) &gt; 1:
            return np.array([self.cdf(v, itc_cap, policy) for v in x])

        # bound and unbunble component values
        x = np.clip(x, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
        x1, x2 = x.reshape(-1)

        # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
        n = len(self.net_demand_data)

        cdf = 0

        for k in range(n):
            net_demand1, net_demand2 = self.net_demand_data[k]
            demand1, demand2 = self.demand_data[k]
            point_cdf = C_API.cond_bivariate_power_margin_cdf_py_interface(
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                np.int32(x1),
                np.int32(x2),
                np.int32(net_demand1),
                np.int32(net_demand2),
                np.int32(demand1),
                np.int32(demand2),
                np.int32(itc_cap),
                np.int32(policy == &#34;share&#34;),
            )

            cdf += point_cdf

        return cdf / n

    def system_lolp(self, itc_cap: int = 1000):
        &#34;&#34;&#34;Computes the system-wide post-interconnection loss of load probability. This is, the probability that at least one area will experience a shortfall.

        Args:
            itc_cap (int, optional): Interconnector capacity

        &#34;&#34;&#34;

        def trapezoid_prob(ulc, c):

            ulc1, ulc2 = ulc
            return C_API.trapezoid_prob_py_interface(
                np.int32(ulc1),
                np.int32(ulc2),
                np.int32(c),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
            )

        n = len(self.net_demand_data)
        gen = self.gen_distribution
        lolp = 0

        c = itc_cap
        for k in range(n):
            net_demand1, net_demand2 = self.net_demand_data[k]
            # system-wide lolp does not depend on the policy
            point_lolp = (
                gen.cdf(np.array([net_demand1 - c - 1, np.Inf]))
                + gen.cdf(np.array([np.Inf, net_demand2 - c - 1]))
                - gen.cdf(np.array([net_demand1 + c, net_demand2 - c - 1]))
                + trapezoid_prob((net_demand1 - c - 1, net_demand2 + c), 2 * c)
            )
            lolp += point_lolp

        return lolp / n

    def lole(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
        &#34;&#34;&#34;
        if area == -1:
            return self.season_length * self.system_lolp(itc_cap)

        x = np.array([np.Inf, np.Inf])
        x[area] = -1
        # m = (-1,np.Inf)
        lolp = self.cdf(x=x, itc_cap=itc_cap, policy=policy)

        return self.season_length * lolp

    def swap_axes(self):
        &#34;&#34;&#34;Utility method to flip components in bivariate distribution objects&#34;&#34;&#34;
        self.demand_data = np.flip(self.demand_data, axis=1)
        self.renewables_data = np.flip(self.renewables_data, axis=1)
        self.net_demand_data = np.flip(self.net_demand_data, axis=1)

        aux = copy.deepcopy(self.convgen1)
        self.convgen1 = copy.deepcopy(self.convgen2)
        self.convgen2 = aux

        self.gen_distribution = Independent(
            x=self.gen_distribution.y, y=self.gen_distribution.x
        )

    def eeu(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
        &#34;&#34;&#34;

        if area == -1:
            return self.eeu(itc_cap, policy, 0) + self.eeu(itc_cap, policy, 1)

        if area == 1:
            self.swap_axes()

        n = len(self.net_demand_data)
        epus = 0

        for k in range(n):
            # print(i)
            net_demand1, net_demand2 = self.net_demand_data[k]
            d1, d2 = self.demand_data[k]
            if policy == &#34;share&#34;:
                point_EPU = C_API.cond_eeu_share_py_interface(
                    np.int32(d1),
                    np.int32(d2),
                    np.int32(net_demand1),
                    np.int32(net_demand2),
                    np.int32(itc_cap),
                    np.int32(self.convgen1[&#34;min&#34;]),
                    np.int32(self.convgen2[&#34;min&#34;]),
                    np.int32(self.convgen1[&#34;max&#34;]),
                    np.int32(self.convgen2[&#34;max&#34;]),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
                )
            elif policy == &#34;veto&#34;:
                point_EPU = C_API.cond_eeu_veto_py_interface(
                    np.int32(net_demand1),
                    np.int32(net_demand2),
                    np.int32(itc_cap),
                    np.int32(self.convgen1[&#34;min&#34;]),
                    np.int32(self.convgen2[&#34;min&#34;]),
                    np.int32(self.convgen1[&#34;max&#34;]),
                    np.int32(self.convgen2[&#34;max&#34;]),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
                )
            else:
                raise ValueError(f&#34;Policy name ({policy}) not recognised.&#34;)

            epus += point_EPU / n

        if area == 1:
            self.swap_axes()

        return epus * self.season_length

    def get_pointwise_risk(
        self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;
    ):
        &#34;&#34;&#34;Calculates the post-interconnection shortfall probability for each one of the net demand observations

        Args:
            x (np.ndarray): point to evaluate CDF at
            itc_cap (int, optional): interconnection capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        pointwise_cdfs = np.empty((len(self.demand_data),))
        for k, (demand_row, renewables_row) in enumerate(
            zip(self.demand_data, self.renewables_data)
        ):
            pointwise_cdfs[k] = type(self)(
                demand_data=demand_row.reshape((1, 2)),
                renewables_data=renewables_row.reshape((1, 2)),
                gen_distribution=self.gen_distribution,
            ).cdf(x=x, itc_cap=itc_cap, policy=policy)

        return pointwise_cdfs

    def simulate(self, size: int, itc_cap: int = 1000, policy=&#34;veto&#34;):
        &#34;&#34;&#34;Simulate the post-interconnection bivariate surplus distribution

        Args:
            size (int): Sample size
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        return self.simulate_region(
            size, np.array([np.Inf, np.Inf]), itc_cap, policy, False
        )

    def simulate_region(
        self,
        size: int,
        upper_bounds: np.ndarray,
        itc_cap: int = 1000,
        policy: str = &#34;veto&#34;,
        shortfall_region: bool = False,
    ):

        &#34;&#34;&#34;Simulate post-interconnection bivariate surplus distribution conditioned to a rectangular region bounded above.

        Args:
            size (int): Sample size
            upper_bounds (np.ndarray): region&#39;s upper bounds
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;
            shortfall_region (bool, optional): If True, upper bounds are ignored and the sampling region becomes the shortfall region, this is, min(S_1, S_2) &lt; 0, or equivalently, that in which at least one area has a shortfall.

        &#34;&#34;&#34;
        seed = np.random.randint(low=0, high=1e8)
        upper_bounds = np.clip(
            upper_bounds, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND
        )
        m1, m2 = upper_bounds
        n = len(self.demand_data)

        simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)
        # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
        ### calculate conditional probability of each historical observation conditioned to the region of interest
        if shortfall_region:
            warnings.warn(
                &#34;Simulating from shortfall region; ignoring passed upper bounds.&#34;,
                stacklevel=2,
            )
            pointwise_cdfs = (
                self.get_pointwise_risk(
                    x=np.array([0, np.Inf]), itc_cap=itc_cap, policy=policy
                )
                + self.get_pointwise_risk(
                    x=np.array([np.Inf, 0]), itc_cap=itc_cap, policy=policy
                )
                - self.get_pointwise_risk(
                    x=np.array([0, 0]), itc_cap=itc_cap, policy=policy
                )
            )
            intersection = False
        else:
            pointwise_cdfs = self.get_pointwise_risk(
                x=upper_bounds, itc_cap=itc_cap, policy=policy
            )
            intersection = True

        # numerical rounding error sometimes output negative probabilities of the order of 1e-30
        pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

        total_prob = np.sum(pointwise_cdfs)
        if total_prob &lt;= 1e-8:
            if fixed_area == 1:
                self.swap_axes()
            raise Exception(
                f&#34;Region has probability {total_prob}; too small to simulate accurately&#34;
            )
        else:
            probs = pointwise_cdfs / total_prob

            samples_per_row = np.random.multinomial(
                n=size, pvals=probs, size=1
            ).reshape((len(probs),))
            nonzero_samples = samples_per_row &gt; 0
            ## only pass rows which induce at least one simulated value
            row_weights = np.ascontiguousarray(
                samples_per_row[nonzero_samples], dtype=np.int32
            )

            net_demand = np.ascontiguousarray(
                self.net_demand_data[nonzero_samples, :], dtype=np.int32
            )

            demand = np.ascontiguousarray(
                self.demand_data[nonzero_samples, :], dtype=np.int32
            )

            C_API.region_simulation_py_interface(
                np.int32(size),
                ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
                np.int32(net_demand.shape[0]),
                np.int32(m1),
                np.int32(m2),
                np.int32(itc_cap),
                int(seed),
                int(intersection),
                int(policy == &#34;share&#34;),
            )

            return simulated

    def simulate_conditional(
        self,
        size: int,
        fixed_value: int,
        fixed_area: int,
        itc_cap: int = 1000,
        policy: str = &#34;veto&#34;,
    ):
        &#34;&#34;&#34;Simulate post-interconnection surplus distribution conditioned to a value in the other area&#39;s surplus

        Args:
            size (int): Sample size
            fixed_value (int): Surplus value conditioned on
            fixed_area (TYPE): Area conditioned on
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        seed = np.random.randint(low=0, high=1e8)
        m1 = np.clip(fixed_value, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
        m2 = self.MARGIN_BOUND

        simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)

        ### calculate conditional probability of each historical observation given
        ### margin value tuple m

        if fixed_area == 0:
            x = np.array([fixed_value, np.Inf])
            y = x - 1
        else:
            x = np.array([np.Inf, fixed_value])
            y = x - 1

        pointwise_cdfs = self.get_pointwise_risk(
            x=x, itc_cap=itc_cap, policy=policy
        ) - self.get_pointwise_risk(x=y, itc_cap=itc_cap, policy=policy)

        pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

        ## rounding errors can make probabilities negative of the order of 1e-60
        total_prob = np.sum(pointwise_cdfs)

        if total_prob &lt;= 1e-12:
            raise Exception(
                f&#34;Region has low probability ({total_prob}); too small to simulate accurately&#34;
            )
        else:
            probs = pointwise_cdfs / total_prob

            samples_per_row = np.random.multinomial(
                n=size, pvals=probs, size=1
            ).reshape((len(probs),))
            nonzero_samples = samples_per_row &gt; 0
            ## only pass rows which induce at least one simulated value
            row_weights = np.ascontiguousarray(
                samples_per_row[nonzero_samples], dtype=np.int32
            )

            if fixed_area == 1:
                self.swap_axes()

            net_demand = np.ascontiguousarray(
                self.net_demand_data[nonzero_samples, :], dtype=np.int32
            )

            demand = np.ascontiguousarray(
                self.demand_data[nonzero_samples, :], dtype=np.int32
            )

            C_API.conditioned_simulation_py_interface(
                np.int32(size),
                ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
                np.int32(net_demand.shape[0]),
                np.int32(m1),
                np.int32(itc_cap),
                int(seed),
                int(policy == &#34;share&#34;),
            )

            if fixed_area == 1:
                self.swap_axes()

        return simulated[
            :, 1
        ]  # first column has variable conditioned on (constant value)


class UnivariateSequential(BaseCapacityModel, BasePydanticModel):

    &#34;&#34;&#34;Univariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type UnivariateTraces.

    Args:
        gen_dir (str): folder with conventional generation data
        demand (np.ndarray): demand data
        renewables (np.ndarray): renewables data
        season_length (int): number of timesteps per peak season
        n_cores (int, optional): number of cores to use for map-reduce operations

    &#34;&#34;&#34;

    gen_dir: str
    demand: np.ndarray
    renewables: np.ndarray
    season_length: int
    n_cores: t.Optional[int] = 2

    _worker_class = UnivariateTraces

    class Config:
        arbitrary_types_allowed = True

    @classmethod
    def _persist_gen_traces(
        cls, args: t.Tuple[acg_models.Sequential, t.Dict, Path, int]
    ) -&gt; None:
        &#34;&#34;&#34;Persists a sequence of traces according to specified arguments as a numpy file

        Args:
            args (t.Tuple[acg_models.Sequential, t.Dict, Path]): trace generation parameters
        &#34;&#34;&#34;
        gen, call_kwargs, filename = args
        traces = gen.simulate_seasons(**call_kwargs)
        np.save(filename, traces)

    @classmethod
    def init(
        cls,
        output_dir: str,
        n_traces: int,
        n_files: int,
        gen: acg_models.Sequential,
        demand: np.ndarray,
        renewables: np.ndarray,
        season_length: int,
        n_cores: int = 4,
        burn_in: int = 100,
        seed: int = None,
    ) -&gt; BaseCapacityModel:
        &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and uses them to instantiate a surplus model. Returns a surplus model ready to perform computations with the generated files.

        Args:
            output_dir (str): Output directory for trace files
            n_traces (int): Total number of season traces to simulate
            n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably optimal.
            gen (acg_models.Sequential): Sequential conventional generation instance.
            demand (np.ndarray): Demand data
            renewables (np.ndarray): renewable generation data
            season_length (int): Peak season length.
            n_cores (int, optional): Number of cores to use.
            burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.
            seed (int, optional): Random seed passed to C backend. If not passed, output file paths are hashed to obtained it; this is because different seeds are needed for each file, otherwise traces are identical across files.

        No Longer Returned:
            UnivariateSequential: Sequential surplus model

        &#34;&#34;&#34;

        # create dir if it doesn&#39;t exist
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        if len(demand) != len(renewables):
            raise ValueError(&#34;demand and renewables must have the same length.&#34;)

        trace_length = len(demand)

        if trace_length % season_length != 0:
            raise ValueError(&#34;trace_length must be divisible by season_length.&#34;)

        if n_traces &lt;= 0 or not isinstance(n_traces, int):
            raise ValueError(&#34;n_traces must be a positive integer&#34;)

        if n_files &lt;= 0 or not isinstance(n_files, int):
            raise ValueError(&#34;n_files must be a positive integer&#34;)

        # compute file size (in terms of number of traces)
        file_sizes = [int(n_traces / n_files) for k in range(n_files)]
        file_sizes[-1] += n_traces - sum(file_sizes)

        # create argument list for multithreaded execution
        arglist = []
        seasons_per_trace = int(trace_length / season_length)
        for idx, file_size in enumerate(file_sizes):
            output_path = Path(output_dir) / str(idx)
            file_seed = (
                seed + idx
                if seed is not None
                else abs(adler32(str(output_path).encode(&#34;utf-8&#34;))) % (1024 * 1024)
            )
            call_kwargs = {
                &#34;size&#34;: file_size,
                &#34;season_length&#34;: season_length,
                &#34;seasons_per_trace&#34;: seasons_per_trace,
                &#34;burn_in&#34;: burn_in,
                &#34;seed&#34;: file_seed,
            }
            arglist.append((gen, call_kwargs, output_path))

        # create files in parallel
        with Pool(n_cores) as executor:
            jobs = list(
                tqdm(
                    executor.imap(cls._persist_gen_traces, arglist), total=len(arglist)
                )
            )

        return cls(
            gen_dir=output_dir,
            demand=np.array(demand),
            renewables=np.array(renewables),
            season_length=season_length,
            n_cores=n_cores,
        )

    def create_mapred_arglist(
        self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict
    ) -&gt; t.List[t.Dict]:
        &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
            str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.

        Returns:
            t.List[t.Any]: Named arguments list
        &#34;&#34;&#34;
        arglist = []
        # create arglist for parallel execution
        for file in Path(self.gen_dir).iterdir():
            kwargs = {
                &#34;gen_filepath&#34;: str(file),
                &#34;demand&#34;: self.demand,
                &#34;renewables&#34;: self.renewables,
                &#34;season_length&#34;: self.season_length,
            }
            arglist.append((kwargs, mapper, str_map_kwargs))

        return arglist

    @classmethod
    def execute_map(
        cls, call_args: t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]
    ) -&gt; t.Tuple[t.Any, int]:
        &#34;&#34;&#34;Instantiate a worker with the passed arguments and execute mapper function on it. Returns both the result of the mapper function and the number of traces processed; the latter is helpful when results from the mappers are aggregated, e.g. global averaging.

        Args:
            call_args (t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]): A triplet with named arguments to instantiate the workers, the function to call on instantiated workers as a string or callable object, and additional unnamed arguments passed to the mapper if given as a string.

        Returns:
            t.Tuple[t.Any, int]: tuple with mapper output and the number of traces processed

        &#34;&#34;&#34;
        worker_kwargs, map_func, str_map_kwargs = call_args
        worker = cls._worker_class(**worker_kwargs)
        n_traces = worker.n_traces
        if isinstance(map_func, str):
            return getattr(worker, map_func)(**str_map_kwargs), n_traces
        elif isinstance(map_func, t.Callable):
            return map_func(worker), n_traces
        else:
            raise ValueError(&#34;map_func must be a string or a function.&#34;)

    def map_reduce(
        self,
        mapper: t.Union[str, t.Callable],
        reducer: t.Optional[t.Callable],
        str_map_kwargs: t.Dict = {},
    ) -&gt; t.Any:
        &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance (of class UnivariateTraces). If a function, it must take as only argument a worker instance.
            reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, no reducer is applied.
            str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper function when passed as a string.

        Returns:
            t.Any: Map-reduce output

        &#34;&#34;&#34;

        arglist = self.create_mapred_arglist(mapper, str_map_kwargs)

        with Pool(self.n_cores) as executor:
            mapped = list(
                tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
            )

        if reducer is not None:
            return reducer(mapped)
        else:
            return mapped

    def cdf(self, x: float) -&gt; float:
        &#34;&#34;&#34;Computes the surplus&#39; cumulative distribution function (CDF) evaluated at a point

        Args:
            x (float): Point at which to evaluate the CDF

        Returns:
            float: CDF estimate
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(mapper=&#34;cdf&#34;, reducer=reducer, str_map_kwargs={&#34;x&#34;: x})

    def simulate(self):
        raise NotImplementedError(
            &#34;This class does not implement a simulate() method. Use get_surplus_df() to get the trace of shortfalls or the full trace of surplus values; alternatively see methods simulate_eu() and simulate_lold().&#34;
        )

    def lole(self) -&gt; float:
        &#34;&#34;&#34;Computes the loss of load expectation

        Returns:
            float: lole estimate
        &#34;&#34;&#34;
        return self.season_length * self.cdf(
            x=-1e-1
        )  # tiny offset to avoid issues with numerical rounding errors from adding millions of numbers together

    def eeu(self):
        &#34;&#34;&#34;Computes the expected energy unserved

        Returns:
            float: eeu estimate
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(mapper=&#34;eeu&#34;, reducer=reducer)

    def simulate_eu(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season energy userved

        Returns:
            np.ndarray: array with one entry per peak season
        &#34;&#34;&#34;

        def reducer(mapped):
            eu_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
            return eu_samples

        return self.map_reduce(mapper=&#34;simulate_eu&#34;, reducer=reducer)

    def simulate_lold(self):
        &#34;&#34;&#34;Simulates per-peak-season loss of load duration

        Returns:
            np.ndarray: array with one entry per peak season
        &#34;&#34;&#34;

        def reducer(mapped):
            lold_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
            return lold_samples

        return self.map_reduce(mapper=&#34;simulate_lold&#34;, reducer=reducer)

    def get_surplus_df(self, shortfalls_only: bool = True) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Returns a data frame with time occurrence information of observed surplus values and shortfalls.

        Args:
            shortfalls_only (bool, optional): If True, only shortfall rows are returned

        Returns:
            pd.DataFrame: A data frame with the surplus values, a &#39;season_time&#39; column with the within-season time of occurrence (0,1,...,season_length-1), a &#39;file_id&#39; column that indicates which file was used to compute the value, and a &#39;season&#39; column to indicate which season the value was observed in.

        &#34;&#34;&#34;

        def reducer(mapped):
            # compute global season number when merging results from different files (each with their own season numbering)
            trace_length = len(self.demand)
            seasons_per_trace = trace_length / self.season_length
            if seasons_per_trace != int(seasons_per_trace):
                raise ValueError(
                    f&#34;trace length ({trace_length}) is not a multiple of season length ({season_length})&#34;
                )
            seasons_per_trace = int(seasons_per_trace)
            past_seasons = 0
            for df, n_traces in mapped:
                df[&#34;season&#34;] += past_seasons
                past_seasons += n_traces * seasons_per_trace
            return pd.concat([df for df, n in mapped])

        return self.map_reduce(
            mapper=&#34;get_surplus_df&#34;,
            reducer=reducer,
            str_map_kwargs={&#34;shortfalls_only&#34;: shortfalls_only},
        )

    def __str__(self):
        return f&#34;Map-reduce based sequential surplus model using trace files in {self.gen_dir}&#34;


class BivariateSequential(UnivariateSequential):

    &#34;&#34;&#34;Bivariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type BivariateTraces.

    Args:
        gen_dir (str): folder with conventional generation data
        demand (np.ndarray): demand data
        renewables (np.ndarray): renewables data
        season_length (int): number of timesteps per peak season
        n_cores (int, optional): number of cores to use for map-reduce operations
    &#34;&#34;&#34;

    _worker_class = BivariateTraces
    _area_indices = [0, 1]

    @property
    def filedirs(self):
        return [Path(self.gen_dir) / str(area) for area in self._area_indices]

    @classmethod
    def init(
        cls,
        output_dir: str,
        n_traces: int,
        n_files: int,
        gens: t.List[acg_models.Sequential],
        demand: np.ndarray,
        renewables: np.ndarray,
        season_length: int,
        n_cores: int = 4,
        burn_in: int = 100,
    ) -&gt; UnivariateSequential:
        &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and use them to instantiate a surplus model.

        Args:
            output_dir (str): output directory for trace files
            n_traces (int): Total number of traces to simulate; a trace is a sequence of at least one peak season
            n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably good enough.
            gens (acg_models.Sequential): List of sequential conventional generation instances, one per system.
            demand (np.ndarray): Demand data
            renewables (np.ndarray): Renewables data
            season_length (int): Peak season length.
            n_cores (int, optional): Number of cores to use.
            burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.

        Returns:
            BivariateSequential: Sequential surplus model


        &#34;&#34;&#34;
        for area, gen, univar_demand, univar_renewables in zip(
            cls._area_indices, gens, demand.T, renewables.T
        ):
            out_dir = Path(output_dir) / str(area)
            print(f&#34;Creating files for area {area}..&#34;)
            UnivariateSequential.init(
                output_dir=str(out_dir),
                n_traces=n_traces,
                n_files=n_files,
                gen=gen,
                demand=univar_demand,
                renewables=univar_renewables,
                season_length=season_length,
                n_cores=n_cores,
                burn_in=burn_in,
            )

        return cls(
            gen_dir=output_dir,
            demand=np.array(demand),
            renewables=np.array(renewables),
            season_length=season_length,
            n_cores=n_cores,
        )

    def create_mapred_arglist(
        self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict, policy: str
    ) -&gt; t.List[t.Dict]:
        &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
            str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.
            policy (str, optional): shortfall-sharing interconnection policy

        Returns:
            t.List[t.Any]: Named arguments list
        &#34;&#34;&#34;
        arglist = []

        # use univariate class logic to build named argument lists, whose instances are then passed as arguments to bivariate models.
        univariate_trace_pairs = []
        for filedir, demand_array, renewables_array in zip(
            self.filedirs, self.demand.T, self.renewables.T
        ):
            univar_model = UnivariateSequential(
                gen_dir=str(filedir),
                demand=demand_array,
                renewables=renewables_array,
                season_length=self.season_length,
            )

            univar_arglist = univar_model.create_mapred_arglist(
                mapper=mapper, str_map_kwargs=str_map_kwargs
            )
            # we only care for named arguments to initialise univariate surplus models
            univariate_trace_pairs.append(
                [UnivariateTraces(**named_args) for named_args, _, _ in univar_arglist]
            )

        # policy is passed here at the worker instantiation level. This is to take advantage of bivariate surplus code from the iid module. Said module implements everything for a veto policy, so it is reused. But said module does not take policy as an argument, and to overcome this in the inheriting subclass, the policy is passed at instantiation time and a reimplementation of the itc_flow method in BivariateTraces looks at the passed value to pick the correct flow equations. This is convoluted but avoids code duplication.

        # each trace here correspond to an area in the system
        for trace_x, trace_y in zip(*univariate_trace_pairs):
            bivariate_args = {
                &#34;univariate_traces&#34;: [trace_x, trace_y],
                &#34;season_length&#34;: self.season_length,
                &#34;policy&#34;: policy,
            }
            arglist.append((bivariate_args, mapper, str_map_kwargs))

        return arglist

    def map_reduce(
        self,
        mapper: t.Union[str, t.Callable],
        reducer: t.Optional[t.Callable],
        str_map_kwargs: t.Dict = {},
        policy: str = &#34;veto&#34;,
        itc_cap: float = 1000.0,
    ) -&gt; t.Any:
        &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method with that name is called on each worker instance (of class `BivariateTraces`). If a function, it must take as only argument a worker instance.
            reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, the mapper output is returned.
            str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper method when passed as a string.
            policy (str, optional): shortfall-sharing interconnection policy
            itc_cap (float, optional): Description

        Returns:
            t.Any: Description

        &#34;&#34;&#34;

        # itc_cap will be passed as an extra named argument to the mapper function, because it is an argument in all of BaseBivariateMonteCarlo methods, which are used to perform the calculations
        str_map_kwargs[&#34;itc_cap&#34;] = itc_cap

        # policy is passed as an argument at worker instantiation time to avoid code duplication. See comments on the create_mapred_arglist method.
        arglist = self.create_mapred_arglist(mapper, str_map_kwargs, policy)

        with Pool(self.n_cores) as executor:
            mapped = list(
                tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
            )

        if reducer is not None:
            return reducer(mapped)
        else:
            return mapped

    def cdf(self, x: np.ndarray, itc_cap: float = 1000.0, policy=&#34;veto&#34;):
        &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

        Args:
            x (np.ndarray): value at which to evaluate the cdf
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(
            mapper=&#34;cdf&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
            str_map_kwargs={&#34;x&#34;: x},
        )

    def lole(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
        &#34;&#34;&#34;
        offset = (
            -1e-1
        )  # this avoids numerical issues from adding up millions of numbers in the calculations
        if area in [0, 1]:
            x = np.zeros((2,), dtype=np.float32) + offset  # tiny offset
            x[1 - area] = np.Inf
            return self.season_length * self.cdf(x, itc_cap=itc_cap, policy=policy)
        elif area == -1:
            x = np.array([offset, np.Inf])
            prob = (
                self.cdf(x, itc_cap=itc_cap, policy=policy)
                + self.cdf(np.flip(x), itc_cap=itc_cap, policy=policy)
                - self.cdf(np.minimum(offset, x), itc_cap=itc_cap, policy=policy)
            )
            return self.season_length * prob
        else:
            raise ValueError(&#34;area must be in [-1,0,1]&#34;)

    def eeu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(
            mapper=&#34;eeu&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
            str_map_kwargs={&#34;area&#34;: area},
        )

    def get_surplus_df(
        self, shortfalls_only: bool = True, itc_cap: float = 1000.0, policy=&#34;veto&#34;
    ) -&gt; pd.DataFrame:
        def reducer(mapped):
            return pd.concat([df for df, n in mapped])

        return self.map_reduce(
            mapper=&#34;get_surplus_df&#34;,
            reducer=reducer,
            str_map_kwargs={&#34;shortfalls_only&#34;: shortfalls_only},
            itc_cap=itc_cap,
            policy=policy,
        )

    def __str__(self):
        return f&#34;Map-reduce based sequential surplus model using trace files in {self.gen_dir}&#34;

    def simulate_eu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season energy unserved for both areas

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

        Returns:
            np.ndarray: array with one row per peak season and one column per area
        &#34;&#34;&#34;

        def reducer(mapped):
            eu_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
            return eu_samples

        return self.map_reduce(
            mapper=&#34;simulate_eu&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
        )

    def simulate_lold(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season loss of load duration for both areas

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

        Returns:
            np.ndarray: array with one row per peak season and one column per area
        &#34;&#34;&#34;

        def reducer(mapped):
            lold_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
            return lold_samples

        return self.map_reduce(
            mapper=&#34;simulate_lold&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
        )</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical"><code class="flex name class">
<span>class <span class="ident">BivariateNSEmpirical</span></span>
<span>(</span><span>demand_data:Â np.ndarray, renewables_data:Â np.ndarray, gen_distribution:Â Independent, season_length:Â intÂ =Â None)</span>
</code></dt>
<dd>
<div class="desc"><p>Non-sequential model that uses a hindcast net demand model to compute exact LOLE and EEU risk indices; it implements both <code>veto</code> and <code>share</code> policies</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>demand_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Demand data matrix with two columns</dd>
<dt><strong><code>gen_distribution</code></strong> :&ensp;<code>Independent</code></dt>
<dd>A bivariate distribution with independent components, where each component is a univar.Binned instance representing the distribution of available conventional generation for the corresponding area</dd>
<dt><strong><code>renewables_data</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Renewable generation data matrix with two columns</dd>
<dt><strong><code>season_length</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>length of peak season. If None, it is set as the length of demand data</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BivariateNSEmpirical(BaseCapacityModel):

    &#34;&#34;&#34;Non-sequential model that uses a hindcast net demand model to compute exact LOLE and EEU risk indices; it implements both `veto` and `share` policies&#34;&#34;&#34;

    def __repr__(self):
        return f&#34;Bivariate empirical surplus model with {len(self.demand_data)} observations&#34;

    def __init__(
        self,
        demand_data: np.ndarray,
        renewables_data: np.ndarray,
        gen_distribution: Independent,
        season_length: int = None,
    ):
        &#34;&#34;&#34;

        Args:
          demand_data (np.ndarray): Demand data matrix with two columns
          gen_distribution (Independent): A bivariate distribution with independent components, where each component is a univar.Binned instance representing the distribution of available conventional generation for the corresponding area
          renewables_data (np.ndarray): Renewable generation data matrix with two columns
          season_length (int, optional): length of peak season. If None, it is set as the length of demand data

        &#34;&#34;&#34;
        warnings.warn(&#34;Coercing data to integer values.&#34;, stacklevel=2)

        self.demand_data = np.ascontiguousarray(demand_data, dtype=np.int32)
        self.renewables_data = np.ascontiguousarray(renewables_data, dtype=np.int32)
        self.net_demand_data = np.ascontiguousarray(
            self.demand_data - self.renewables_data
        )

        if not isinstance(gen_distribution.x, univar.Binned) or not isinstance(
            gen_distribution.y, univar.Binned
        ):
            raise TypeError(
                &#34;Marginal generation distributions must be instances of Binned (i.e. integer support).&#34;
            )

        # save hard copy of relevant arrays from generation
        # this is needed because strange things happened when copying arrays directly from the Independent instance. This somehow solves the issue
        self.convgen1 = {
            &#34;min&#34;: gen_distribution.x.min,
            &#34;max&#34;: gen_distribution.x.max,
            &#34;cdf_values&#34;: np.ascontiguousarray(
                np.copy(gen_distribution.x.cdf_values, order=&#34;C&#34;)
            ),
            &#34;expectation_vals&#34;: np.ascontiguousarray(
                np.cumsum(gen_distribution.x.support * gen_distribution.x.pdf_values)
            ),
        }

        self.convgen2 = {
            &#34;min&#34;: gen_distribution.y.min,
            &#34;max&#34;: gen_distribution.y.max,
            &#34;cdf_values&#34;: np.ascontiguousarray(
                np.copy(gen_distribution.y.cdf_values, order=&#34;C&#34;)
            ),
            &#34;expectation_vals&#34;: np.ascontiguousarray(
                np.cumsum(gen_distribution.y.support * gen_distribution.y.pdf_values)
            ),
        }

        self.gen_distribution = gen_distribution
        self.MARGIN_BOUND = int(np.iinfo(np.int32).max / 2)

        if season_length is None:
            warnings.warn(&#34;Using length of demand data as season length.&#34;, stacklevel=2)
        self.season_length = (
            len(self.demand_data) if season_length is None else season_length
        )

    def cdf(self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;):
        &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

        Args:
            x (np.ndarray): value at which to evaluate the cdf
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

        &#34;&#34;&#34;

        # if x is an n x 2 matrix
        if len(x.shape) == 2 and len(x) &gt; 1:
            return np.array([self.cdf(v, itc_cap, policy) for v in x])

        # bound and unbunble component values
        x = np.clip(x, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
        x1, x2 = x.reshape(-1)

        # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
        n = len(self.net_demand_data)

        cdf = 0

        for k in range(n):
            net_demand1, net_demand2 = self.net_demand_data[k]
            demand1, demand2 = self.demand_data[k]
            point_cdf = C_API.cond_bivariate_power_margin_cdf_py_interface(
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                np.int32(x1),
                np.int32(x2),
                np.int32(net_demand1),
                np.int32(net_demand2),
                np.int32(demand1),
                np.int32(demand2),
                np.int32(itc_cap),
                np.int32(policy == &#34;share&#34;),
            )

            cdf += point_cdf

        return cdf / n

    def system_lolp(self, itc_cap: int = 1000):
        &#34;&#34;&#34;Computes the system-wide post-interconnection loss of load probability. This is, the probability that at least one area will experience a shortfall.

        Args:
            itc_cap (int, optional): Interconnector capacity

        &#34;&#34;&#34;

        def trapezoid_prob(ulc, c):

            ulc1, ulc2 = ulc
            return C_API.trapezoid_prob_py_interface(
                np.int32(ulc1),
                np.int32(ulc2),
                np.int32(c),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
            )

        n = len(self.net_demand_data)
        gen = self.gen_distribution
        lolp = 0

        c = itc_cap
        for k in range(n):
            net_demand1, net_demand2 = self.net_demand_data[k]
            # system-wide lolp does not depend on the policy
            point_lolp = (
                gen.cdf(np.array([net_demand1 - c - 1, np.Inf]))
                + gen.cdf(np.array([np.Inf, net_demand2 - c - 1]))
                - gen.cdf(np.array([net_demand1 + c, net_demand2 - c - 1]))
                + trapezoid_prob((net_demand1 - c - 1, net_demand2 + c), 2 * c)
            )
            lolp += point_lolp

        return lolp / n

    def lole(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
        &#34;&#34;&#34;
        if area == -1:
            return self.season_length * self.system_lolp(itc_cap)

        x = np.array([np.Inf, np.Inf])
        x[area] = -1
        # m = (-1,np.Inf)
        lolp = self.cdf(x=x, itc_cap=itc_cap, policy=policy)

        return self.season_length * lolp

    def swap_axes(self):
        &#34;&#34;&#34;Utility method to flip components in bivariate distribution objects&#34;&#34;&#34;
        self.demand_data = np.flip(self.demand_data, axis=1)
        self.renewables_data = np.flip(self.renewables_data, axis=1)
        self.net_demand_data = np.flip(self.net_demand_data, axis=1)

        aux = copy.deepcopy(self.convgen1)
        self.convgen1 = copy.deepcopy(self.convgen2)
        self.convgen2 = aux

        self.gen_distribution = Independent(
            x=self.gen_distribution.y, y=self.gen_distribution.x
        )

    def eeu(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
        &#34;&#34;&#34;

        if area == -1:
            return self.eeu(itc_cap, policy, 0) + self.eeu(itc_cap, policy, 1)

        if area == 1:
            self.swap_axes()

        n = len(self.net_demand_data)
        epus = 0

        for k in range(n):
            # print(i)
            net_demand1, net_demand2 = self.net_demand_data[k]
            d1, d2 = self.demand_data[k]
            if policy == &#34;share&#34;:
                point_EPU = C_API.cond_eeu_share_py_interface(
                    np.int32(d1),
                    np.int32(d2),
                    np.int32(net_demand1),
                    np.int32(net_demand2),
                    np.int32(itc_cap),
                    np.int32(self.convgen1[&#34;min&#34;]),
                    np.int32(self.convgen2[&#34;min&#34;]),
                    np.int32(self.convgen1[&#34;max&#34;]),
                    np.int32(self.convgen2[&#34;max&#34;]),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
                )
            elif policy == &#34;veto&#34;:
                point_EPU = C_API.cond_eeu_veto_py_interface(
                    np.int32(net_demand1),
                    np.int32(net_demand2),
                    np.int32(itc_cap),
                    np.int32(self.convgen1[&#34;min&#34;]),
                    np.int32(self.convgen2[&#34;min&#34;]),
                    np.int32(self.convgen1[&#34;max&#34;]),
                    np.int32(self.convgen2[&#34;max&#34;]),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                    ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
                )
            else:
                raise ValueError(f&#34;Policy name ({policy}) not recognised.&#34;)

            epus += point_EPU / n

        if area == 1:
            self.swap_axes()

        return epus * self.season_length

    def get_pointwise_risk(
        self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;
    ):
        &#34;&#34;&#34;Calculates the post-interconnection shortfall probability for each one of the net demand observations

        Args:
            x (np.ndarray): point to evaluate CDF at
            itc_cap (int, optional): interconnection capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        pointwise_cdfs = np.empty((len(self.demand_data),))
        for k, (demand_row, renewables_row) in enumerate(
            zip(self.demand_data, self.renewables_data)
        ):
            pointwise_cdfs[k] = type(self)(
                demand_data=demand_row.reshape((1, 2)),
                renewables_data=renewables_row.reshape((1, 2)),
                gen_distribution=self.gen_distribution,
            ).cdf(x=x, itc_cap=itc_cap, policy=policy)

        return pointwise_cdfs

    def simulate(self, size: int, itc_cap: int = 1000, policy=&#34;veto&#34;):
        &#34;&#34;&#34;Simulate the post-interconnection bivariate surplus distribution

        Args:
            size (int): Sample size
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        return self.simulate_region(
            size, np.array([np.Inf, np.Inf]), itc_cap, policy, False
        )

    def simulate_region(
        self,
        size: int,
        upper_bounds: np.ndarray,
        itc_cap: int = 1000,
        policy: str = &#34;veto&#34;,
        shortfall_region: bool = False,
    ):

        &#34;&#34;&#34;Simulate post-interconnection bivariate surplus distribution conditioned to a rectangular region bounded above.

        Args:
            size (int): Sample size
            upper_bounds (np.ndarray): region&#39;s upper bounds
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;
            shortfall_region (bool, optional): If True, upper bounds are ignored and the sampling region becomes the shortfall region, this is, min(S_1, S_2) &lt; 0, or equivalently, that in which at least one area has a shortfall.

        &#34;&#34;&#34;
        seed = np.random.randint(low=0, high=1e8)
        upper_bounds = np.clip(
            upper_bounds, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND
        )
        m1, m2 = upper_bounds
        n = len(self.demand_data)

        simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)
        # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
        ### calculate conditional probability of each historical observation conditioned to the region of interest
        if shortfall_region:
            warnings.warn(
                &#34;Simulating from shortfall region; ignoring passed upper bounds.&#34;,
                stacklevel=2,
            )
            pointwise_cdfs = (
                self.get_pointwise_risk(
                    x=np.array([0, np.Inf]), itc_cap=itc_cap, policy=policy
                )
                + self.get_pointwise_risk(
                    x=np.array([np.Inf, 0]), itc_cap=itc_cap, policy=policy
                )
                - self.get_pointwise_risk(
                    x=np.array([0, 0]), itc_cap=itc_cap, policy=policy
                )
            )
            intersection = False
        else:
            pointwise_cdfs = self.get_pointwise_risk(
                x=upper_bounds, itc_cap=itc_cap, policy=policy
            )
            intersection = True

        # numerical rounding error sometimes output negative probabilities of the order of 1e-30
        pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

        total_prob = np.sum(pointwise_cdfs)
        if total_prob &lt;= 1e-8:
            if fixed_area == 1:
                self.swap_axes()
            raise Exception(
                f&#34;Region has probability {total_prob}; too small to simulate accurately&#34;
            )
        else:
            probs = pointwise_cdfs / total_prob

            samples_per_row = np.random.multinomial(
                n=size, pvals=probs, size=1
            ).reshape((len(probs),))
            nonzero_samples = samples_per_row &gt; 0
            ## only pass rows which induce at least one simulated value
            row_weights = np.ascontiguousarray(
                samples_per_row[nonzero_samples], dtype=np.int32
            )

            net_demand = np.ascontiguousarray(
                self.net_demand_data[nonzero_samples, :], dtype=np.int32
            )

            demand = np.ascontiguousarray(
                self.demand_data[nonzero_samples, :], dtype=np.int32
            )

            C_API.region_simulation_py_interface(
                np.int32(size),
                ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
                np.int32(net_demand.shape[0]),
                np.int32(m1),
                np.int32(m2),
                np.int32(itc_cap),
                int(seed),
                int(intersection),
                int(policy == &#34;share&#34;),
            )

            return simulated

    def simulate_conditional(
        self,
        size: int,
        fixed_value: int,
        fixed_area: int,
        itc_cap: int = 1000,
        policy: str = &#34;veto&#34;,
    ):
        &#34;&#34;&#34;Simulate post-interconnection surplus distribution conditioned to a value in the other area&#39;s surplus

        Args:
            size (int): Sample size
            fixed_value (int): Surplus value conditioned on
            fixed_area (TYPE): Area conditioned on
            itc_cap (int, optional): Interconnector capacity
            policy (str): one of &#39;veto&#39; or &#39;share&#39;

        &#34;&#34;&#34;
        seed = np.random.randint(low=0, high=1e8)
        m1 = np.clip(fixed_value, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
        m2 = self.MARGIN_BOUND

        simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)

        ### calculate conditional probability of each historical observation given
        ### margin value tuple m

        if fixed_area == 0:
            x = np.array([fixed_value, np.Inf])
            y = x - 1
        else:
            x = np.array([np.Inf, fixed_value])
            y = x - 1

        pointwise_cdfs = self.get_pointwise_risk(
            x=x, itc_cap=itc_cap, policy=policy
        ) - self.get_pointwise_risk(x=y, itc_cap=itc_cap, policy=policy)

        pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

        ## rounding errors can make probabilities negative of the order of 1e-60
        total_prob = np.sum(pointwise_cdfs)

        if total_prob &lt;= 1e-12:
            raise Exception(
                f&#34;Region has low probability ({total_prob}); too small to simulate accurately&#34;
            )
        else:
            probs = pointwise_cdfs / total_prob

            samples_per_row = np.random.multinomial(
                n=size, pvals=probs, size=1
            ).reshape((len(probs),))
            nonzero_samples = samples_per_row &gt; 0
            ## only pass rows which induce at least one simulated value
            row_weights = np.ascontiguousarray(
                samples_per_row[nonzero_samples], dtype=np.int32
            )

            if fixed_area == 1:
                self.swap_axes()

            net_demand = np.ascontiguousarray(
                self.net_demand_data[nonzero_samples, :], dtype=np.int32
            )

            demand = np.ascontiguousarray(
                self.demand_data[nonzero_samples, :], dtype=np.int32
            )

            C_API.conditioned_simulation_py_interface(
                np.int32(size),
                ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, demand.ctypes.data),
                ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
                np.int32(net_demand.shape[0]),
                np.int32(m1),
                np.int32(itc_cap),
                int(seed),
                int(policy == &#34;share&#34;),
            )

            if fixed_area == 1:
                self.swap_axes()

        return simulated[
            :, 1
        ]  # first column has variable conditioned on (constant value)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="riskmodels.utils.adequacy_interfaces.BaseCapacityModel" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseCapacityModel">BaseCapacityModel</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.cdf"><code class="name flex">
<span>def <span class="ident">cdf</span></span>(<span>self, x:Â np.ndarray, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto')</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluates the bivariate post-interconnection capacity surplus distribution's cumulative distribution function</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>value at which to evaluate the cdf</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cdf(self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;):
    &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

    Args:
        x (np.ndarray): value at which to evaluate the cdf
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

    &#34;&#34;&#34;

    # if x is an n x 2 matrix
    if len(x.shape) == 2 and len(x) &gt; 1:
        return np.array([self.cdf(v, itc_cap, policy) for v in x])

    # bound and unbunble component values
    x = np.clip(x, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
    x1, x2 = x.reshape(-1)

    # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
    n = len(self.net_demand_data)

    cdf = 0

    for k in range(n):
        net_demand1, net_demand2 = self.net_demand_data[k]
        demand1, demand2 = self.demand_data[k]
        point_cdf = C_API.cond_bivariate_power_margin_cdf_py_interface(
            np.int32(self.convgen1[&#34;min&#34;]),
            np.int32(self.convgen2[&#34;min&#34;]),
            np.int32(self.convgen1[&#34;max&#34;]),
            np.int32(self.convgen2[&#34;max&#34;]),
            ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
            np.int32(x1),
            np.int32(x2),
            np.int32(net_demand1),
            np.int32(net_demand2),
            np.int32(demand1),
            np.int32(demand2),
            np.int32(itc_cap),
            np.int32(policy == &#34;share&#34;),
        )

        cdf += point_cdf

    return cdf / n</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.eeu"><code class="name flex">
<span>def <span class="ident">eeu</span></span>(<span>self, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto', area:Â intÂ =Â 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the post-interconnection expected energy unserved.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.</dd>
<dt><strong><code>area</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Area for which to evaluate eeu; if area=-1, systemwide eeu is returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eeu(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
    &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
        area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
    &#34;&#34;&#34;

    if area == -1:
        return self.eeu(itc_cap, policy, 0) + self.eeu(itc_cap, policy, 1)

    if area == 1:
        self.swap_axes()

    n = len(self.net_demand_data)
    epus = 0

    for k in range(n):
        # print(i)
        net_demand1, net_demand2 = self.net_demand_data[k]
        d1, d2 = self.demand_data[k]
        if policy == &#34;share&#34;:
            point_EPU = C_API.cond_eeu_share_py_interface(
                np.int32(d1),
                np.int32(d2),
                np.int32(net_demand1),
                np.int32(net_demand2),
                np.int32(itc_cap),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
            )
        elif policy == &#34;veto&#34;:
            point_EPU = C_API.cond_eeu_veto_py_interface(
                np.int32(net_demand1),
                np.int32(net_demand2),
                np.int32(itc_cap),
                np.int32(self.convgen1[&#34;min&#34;]),
                np.int32(self.convgen2[&#34;min&#34;]),
                np.int32(self.convgen1[&#34;max&#34;]),
                np.int32(self.convgen2[&#34;max&#34;]),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
                ffi.cast(&#34;double *&#34;, self.convgen1[&#34;expectation_vals&#34;].ctypes.data),
            )
        else:
            raise ValueError(f&#34;Policy name ({policy}) not recognised.&#34;)

        epus += point_EPU / n

    if area == 1:
        self.swap_axes()

    return epus * self.season_length</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.get_pointwise_risk"><code class="name flex">
<span>def <span class="ident">get_pointwise_risk</span></span>(<span>self, x:Â np.ndarray, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto')</span>
</code></dt>
<dd>
<div class="desc"><p>Calculates the post-interconnection shortfall probability for each one of the net demand observations</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>point to evaluate CDF at</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code></dt>
<dd>one of 'veto' or 'share'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pointwise_risk(
    self, x: np.ndarray, itc_cap: int = 1000, policy: str = &#34;veto&#34;
):
    &#34;&#34;&#34;Calculates the post-interconnection shortfall probability for each one of the net demand observations

    Args:
        x (np.ndarray): point to evaluate CDF at
        itc_cap (int, optional): interconnection capacity
        policy (str): one of &#39;veto&#39; or &#39;share&#39;

    &#34;&#34;&#34;
    pointwise_cdfs = np.empty((len(self.demand_data),))
    for k, (demand_row, renewables_row) in enumerate(
        zip(self.demand_data, self.renewables_data)
    ):
        pointwise_cdfs[k] = type(self)(
            demand_data=demand_row.reshape((1, 2)),
            renewables_data=renewables_row.reshape((1, 2)),
            gen_distribution=self.gen_distribution,
        ).cdf(x=x, itc_cap=itc_cap, policy=policy)

    return pointwise_cdfs</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.lole"><code class="name flex">
<span>def <span class="ident">lole</span></span>(<span>self, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto', area:Â intÂ =Â 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the post-interconnection loss of load expectation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.</dd>
<dt><strong><code>area</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Area for which to evaluate LOLE; if area=-1, system-wide lole is returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lole(self, itc_cap: int = 1000, policy: str = &#34;veto&#34;, area: int = 0):
    &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.
        area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
    &#34;&#34;&#34;
    if area == -1:
        return self.season_length * self.system_lolp(itc_cap)

    x = np.array([np.Inf, np.Inf])
    x[area] = -1
    # m = (-1,np.Inf)
    lolp = self.cdf(x=x, itc_cap=itc_cap, policy=policy)

    return self.season_length * lolp</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate"><code class="name flex">
<span>def <span class="ident">simulate</span></span>(<span>self, size:Â int, itc_cap:Â intÂ =Â 1000, policy='veto')</span>
</code></dt>
<dd>
<div class="desc"><p>Simulate the post-interconnection bivariate surplus distribution</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Sample size</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Interconnector capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code></dt>
<dd>one of 'veto' or 'share'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate(self, size: int, itc_cap: int = 1000, policy=&#34;veto&#34;):
    &#34;&#34;&#34;Simulate the post-interconnection bivariate surplus distribution

    Args:
        size (int): Sample size
        itc_cap (int, optional): Interconnector capacity
        policy (str): one of &#39;veto&#39; or &#39;share&#39;

    &#34;&#34;&#34;
    return self.simulate_region(
        size, np.array([np.Inf, np.Inf]), itc_cap, policy, False
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_conditional"><code class="name flex">
<span>def <span class="ident">simulate_conditional</span></span>(<span>self, size:Â int, fixed_value:Â int, fixed_area:Â int, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto')</span>
</code></dt>
<dd>
<div class="desc"><p>Simulate post-interconnection surplus distribution conditioned to a value in the other area's surplus</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Sample size</dd>
<dt><strong><code>fixed_value</code></strong> :&ensp;<code>int</code></dt>
<dd>Surplus value conditioned on</dd>
<dt><strong><code>fixed_area</code></strong> :&ensp;<code>TYPE</code></dt>
<dd>Area conditioned on</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Interconnector capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code></dt>
<dd>one of 'veto' or 'share'</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_conditional(
    self,
    size: int,
    fixed_value: int,
    fixed_area: int,
    itc_cap: int = 1000,
    policy: str = &#34;veto&#34;,
):
    &#34;&#34;&#34;Simulate post-interconnection surplus distribution conditioned to a value in the other area&#39;s surplus

    Args:
        size (int): Sample size
        fixed_value (int): Surplus value conditioned on
        fixed_area (TYPE): Area conditioned on
        itc_cap (int, optional): Interconnector capacity
        policy (str): one of &#39;veto&#39; or &#39;share&#39;

    &#34;&#34;&#34;
    seed = np.random.randint(low=0, high=1e8)
    m1 = np.clip(fixed_value, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND)
    m2 = self.MARGIN_BOUND

    simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)

    ### calculate conditional probability of each historical observation given
    ### margin value tuple m

    if fixed_area == 0:
        x = np.array([fixed_value, np.Inf])
        y = x - 1
    else:
        x = np.array([np.Inf, fixed_value])
        y = x - 1

    pointwise_cdfs = self.get_pointwise_risk(
        x=x, itc_cap=itc_cap, policy=policy
    ) - self.get_pointwise_risk(x=y, itc_cap=itc_cap, policy=policy)

    pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

    ## rounding errors can make probabilities negative of the order of 1e-60
    total_prob = np.sum(pointwise_cdfs)

    if total_prob &lt;= 1e-12:
        raise Exception(
            f&#34;Region has low probability ({total_prob}); too small to simulate accurately&#34;
        )
    else:
        probs = pointwise_cdfs / total_prob

        samples_per_row = np.random.multinomial(
            n=size, pvals=probs, size=1
        ).reshape((len(probs),))
        nonzero_samples = samples_per_row &gt; 0
        ## only pass rows which induce at least one simulated value
        row_weights = np.ascontiguousarray(
            samples_per_row[nonzero_samples], dtype=np.int32
        )

        if fixed_area == 1:
            self.swap_axes()

        net_demand = np.ascontiguousarray(
            self.net_demand_data[nonzero_samples, :], dtype=np.int32
        )

        demand = np.ascontiguousarray(
            self.demand_data[nonzero_samples, :], dtype=np.int32
        )

        C_API.conditioned_simulation_py_interface(
            np.int32(size),
            ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
            np.int32(self.convgen1[&#34;min&#34;]),
            np.int32(self.convgen2[&#34;min&#34;]),
            np.int32(self.convgen1[&#34;max&#34;]),
            np.int32(self.convgen2[&#34;max&#34;]),
            ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
            ffi.cast(&#34;int *&#34;, demand.ctypes.data),
            ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
            np.int32(net_demand.shape[0]),
            np.int32(m1),
            np.int32(itc_cap),
            int(seed),
            int(policy == &#34;share&#34;),
        )

        if fixed_area == 1:
            self.swap_axes()

    return simulated[
        :, 1
    ]  # first column has variable conditioned on (constant value)</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_region"><code class="name flex">
<span>def <span class="ident">simulate_region</span></span>(<span>self, size:Â int, upper_bounds:Â np.ndarray, itc_cap:Â intÂ =Â 1000, policy:Â strÂ =Â 'veto', shortfall_region:Â boolÂ =Â False)</span>
</code></dt>
<dd>
<div class="desc"><p>Simulate post-interconnection bivariate surplus distribution conditioned to a rectangular region bounded above.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Sample size</dd>
<dt><strong><code>upper_bounds</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>region's upper bounds</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Interconnector capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code></dt>
<dd>one of 'veto' or 'share'</dd>
<dt><strong><code>shortfall_region</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, upper bounds are ignored and the sampling region becomes the shortfall region, this is, min(S_1, S_2) &lt; 0, or equivalently, that in which at least one area has a shortfall.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_region(
    self,
    size: int,
    upper_bounds: np.ndarray,
    itc_cap: int = 1000,
    policy: str = &#34;veto&#34;,
    shortfall_region: bool = False,
):

    &#34;&#34;&#34;Simulate post-interconnection bivariate surplus distribution conditioned to a rectangular region bounded above.

    Args:
        size (int): Sample size
        upper_bounds (np.ndarray): region&#39;s upper bounds
        itc_cap (int, optional): Interconnector capacity
        policy (str): one of &#39;veto&#39; or &#39;share&#39;
        shortfall_region (bool, optional): If True, upper bounds are ignored and the sampling region becomes the shortfall region, this is, min(S_1, S_2) &lt; 0, or equivalently, that in which at least one area has a shortfall.

    &#34;&#34;&#34;
    seed = np.random.randint(low=0, high=1e8)
    upper_bounds = np.clip(
        upper_bounds, a_min=-self.MARGIN_BOUND, a_max=self.MARGIN_BOUND
    )
    m1, m2 = upper_bounds
    n = len(self.demand_data)

    simulated = np.ascontiguousarray(np.zeros((size, 2)), dtype=np.int32)
    # convgen1, convgen2 = self.gen_distribution.x, self.gen_distribution.y
    ### calculate conditional probability of each historical observation conditioned to the region of interest
    if shortfall_region:
        warnings.warn(
            &#34;Simulating from shortfall region; ignoring passed upper bounds.&#34;,
            stacklevel=2,
        )
        pointwise_cdfs = (
            self.get_pointwise_risk(
                x=np.array([0, np.Inf]), itc_cap=itc_cap, policy=policy
            )
            + self.get_pointwise_risk(
                x=np.array([np.Inf, 0]), itc_cap=itc_cap, policy=policy
            )
            - self.get_pointwise_risk(
                x=np.array([0, 0]), itc_cap=itc_cap, policy=policy
            )
        )
        intersection = False
    else:
        pointwise_cdfs = self.get_pointwise_risk(
            x=upper_bounds, itc_cap=itc_cap, policy=policy
        )
        intersection = True

    # numerical rounding error sometimes output negative probabilities of the order of 1e-30
    pointwise_cdfs = np.clip(pointwise_cdfs, a_min=0.0, a_max=np.Inf)

    total_prob = np.sum(pointwise_cdfs)
    if total_prob &lt;= 1e-8:
        if fixed_area == 1:
            self.swap_axes()
        raise Exception(
            f&#34;Region has probability {total_prob}; too small to simulate accurately&#34;
        )
    else:
        probs = pointwise_cdfs / total_prob

        samples_per_row = np.random.multinomial(
            n=size, pvals=probs, size=1
        ).reshape((len(probs),))
        nonzero_samples = samples_per_row &gt; 0
        ## only pass rows which induce at least one simulated value
        row_weights = np.ascontiguousarray(
            samples_per_row[nonzero_samples], dtype=np.int32
        )

        net_demand = np.ascontiguousarray(
            self.net_demand_data[nonzero_samples, :], dtype=np.int32
        )

        demand = np.ascontiguousarray(
            self.demand_data[nonzero_samples, :], dtype=np.int32
        )

        C_API.region_simulation_py_interface(
            np.int32(size),
            ffi.cast(&#34;int *&#34;, simulated.ctypes.data),
            np.int32(self.convgen1[&#34;min&#34;]),
            np.int32(self.convgen2[&#34;min&#34;]),
            np.int32(self.convgen1[&#34;max&#34;]),
            np.int32(self.convgen2[&#34;max&#34;]),
            ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;int *&#34;, net_demand.ctypes.data),
            ffi.cast(&#34;int *&#34;, demand.ctypes.data),
            ffi.cast(&#34;int *&#34;, row_weights.ctypes.data),
            np.int32(net_demand.shape[0]),
            np.int32(m1),
            np.int32(m2),
            np.int32(itc_cap),
            int(seed),
            int(intersection),
            int(policy == &#34;share&#34;),
        )

        return simulated</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.swap_axes"><code class="name flex">
<span>def <span class="ident">swap_axes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Utility method to flip components in bivariate distribution objects</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def swap_axes(self):
    &#34;&#34;&#34;Utility method to flip components in bivariate distribution objects&#34;&#34;&#34;
    self.demand_data = np.flip(self.demand_data, axis=1)
    self.renewables_data = np.flip(self.renewables_data, axis=1)
    self.net_demand_data = np.flip(self.net_demand_data, axis=1)

    aux = copy.deepcopy(self.convgen1)
    self.convgen1 = copy.deepcopy(self.convgen2)
    self.convgen2 = aux

    self.gen_distribution = Independent(
        x=self.gen_distribution.y, y=self.gen_distribution.x
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.system_lolp"><code class="name flex">
<span>def <span class="ident">system_lolp</span></span>(<span>self, itc_cap:Â intÂ =Â 1000)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the system-wide post-interconnection loss of load probability. This is, the probability that at least one area will experience a shortfall.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Interconnector capacity</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def system_lolp(self, itc_cap: int = 1000):
    &#34;&#34;&#34;Computes the system-wide post-interconnection loss of load probability. This is, the probability that at least one area will experience a shortfall.

    Args:
        itc_cap (int, optional): Interconnector capacity

    &#34;&#34;&#34;

    def trapezoid_prob(ulc, c):

        ulc1, ulc2 = ulc
        return C_API.trapezoid_prob_py_interface(
            np.int32(ulc1),
            np.int32(ulc2),
            np.int32(c),
            np.int32(self.convgen1[&#34;min&#34;]),
            np.int32(self.convgen2[&#34;min&#34;]),
            np.int32(self.convgen1[&#34;max&#34;]),
            np.int32(self.convgen2[&#34;max&#34;]),
            ffi.cast(&#34;double *&#34;, self.convgen1[&#34;cdf_values&#34;].ctypes.data),
            ffi.cast(&#34;double *&#34;, self.convgen2[&#34;cdf_values&#34;].ctypes.data),
        )

    n = len(self.net_demand_data)
    gen = self.gen_distribution
    lolp = 0

    c = itc_cap
    for k in range(n):
        net_demand1, net_demand2 = self.net_demand_data[k]
        # system-wide lolp does not depend on the policy
        point_lolp = (
            gen.cdf(np.array([net_demand1 - c - 1, np.Inf]))
            + gen.cdf(np.array([np.Inf, net_demand2 - c - 1]))
            - gen.cdf(np.array([net_demand1 + c, net_demand2 - c - 1]))
            + trapezoid_prob((net_demand1 - c - 1, net_demand2 + c), 2 * c)
        )
        lolp += point_lolp

    return lolp / n</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo"><code class="flex name class">
<span>class <span class="ident">BivariateNSMonteCarlo</span></span>
<span>(</span><span>**data:Â Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Non-sequential bivariate capacity surplus model that takes arbitrary bivariate distributions (inheriting from <code><a title="riskmodels.bivariate.BaseDistribution" href="../bivariate.html#riskmodels.bivariate.BaseDistribution">BaseDistribution</a></code>) for ACG and net demand. It calculates time-collapsed risk metrics by simulation and only implements a veto policy between areas, this is, areas will only export spare available capacity. For models that implement a <code>share</code> policy, see <code><a title="riskmodels.adequacy.capacity_models.BivariateSequential" href="#riskmodels.adequacy.capacity_models.BivariateSequential">BivariateSequential</a></code> and <code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical">BivariateNSEmpirical</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>gen_distribution</code></strong> :&ensp;<code>BaseDistribution</code></dt>
<dd>available conventional generation distribution</dd>
<dt><strong><code>net_demand</code></strong> :&ensp;<code>BaseDistribution</code></dt>
<dd>net demand distribution</dd>
<dt><strong><code>size</code></strong> :&ensp;<code>int</code></dt>
<dd>Sample size for Monte Carlo estimation</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BivariateNSMonteCarlo(BaseBivariateMonteCarlo):

    &#34;&#34;&#34;Non-sequential bivariate capacity surplus model that takes arbitrary bivariate distributions (inheriting from `riskmodels.bivariate.BaseDistribution`) for ACG and net demand. It calculates time-collapsed risk metrics by simulation and only implements a veto policy between areas, this is, areas will only export spare available capacity. For models that implement a `share` policy, see `BivariateSequential` and `BivariateNSEmpirical`.

    Args:
        gen_distribution (BaseDistribution): available conventional generation distribution
        net_demand (BaseDistribution): net demand distribution
        size (int): Sample size for Monte Carlo estimation

    &#34;&#34;&#34;

    gen_distribution: BaseDistribution
    net_demand: BaseDistribution
    size: int

    class Config:
        arbitrary_types_allowed = True

    def get_pre_itc_sample(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Returns a pre-interconnection surplus sample by simulating the passed bivariate distributions for available conventional generation and net demand

        Returns:
            np.ndarray: Sample
        &#34;&#34;&#34;
        return self.gen_distribution.simulate(self.size) - self.net_demand.simulate(
            self.size
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo">BaseBivariateMonteCarlo</a></li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
<li><a title="riskmodels.utils.adequacy_interfaces.BaseCapacityModel" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseCapacityModel">BaseCapacityModel</a></li>
<li>abc.ABC</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.Config"><code class="name">var <span class="ident">Config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.gen_distribution"><code class="name">var <span class="ident">gen_distribution</span> :Â <a title="riskmodels.bivariate.BaseDistribution" href="../bivariate.html#riskmodels.bivariate.BaseDistribution">BaseDistribution</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.net_demand"><code class="name">var <span class="ident">net_demand</span> :Â <a title="riskmodels.bivariate.BaseDistribution" href="../bivariate.html#riskmodels.bivariate.BaseDistribution">BaseDistribution</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.size"><code class="name">var <span class="ident">size</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.get_pre_itc_sample"><code class="name flex">
<span>def <span class="ident">get_pre_itc_sample</span></span>(<span>self) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pre-interconnection surplus sample by simulating the passed bivariate distributions for available conventional generation and net demand</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Sample</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_pre_itc_sample(self) -&gt; np.ndarray:
    &#34;&#34;&#34;Returns a pre-interconnection surplus sample by simulating the passed bivariate distributions for available conventional generation and net demand

    Returns:
        np.ndarray: Sample
    &#34;&#34;&#34;
    return self.gen_distribution.simulate(self.size) - self.net_demand.simulate(
        self.size
    )</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo">BaseBivariateMonteCarlo</a></b></code>:
<ul class="hlist">
<li><code><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.cdf" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.cdf">cdf</a></code></li>
<li><code><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.eeu" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.eeu">eeu</a></code></li>
<li><code><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.itc_flow" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.itc_flow">itc_flow</a></code></li>
<li><code><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.lole" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.lole">lole</a></code></li>
<li><code><a title="riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.simulate" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseBivariateMonteCarlo.simulate">simulate</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential"><code class="flex name class">
<span>class <span class="ident">BivariateSequential</span></span>
<span>(</span><span>**data:Â Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Bivariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type BivariateTraces.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>gen_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>folder with conventional generation data</dd>
<dt><strong><code>demand</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>demand data</dd>
<dt><strong><code>renewables</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>renewables data</dd>
<dt><strong><code>season_length</code></strong> :&ensp;<code>int</code></dt>
<dd>number of timesteps per peak season</dd>
<dt><strong><code>n_cores</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>number of cores to use for map-reduce operations</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BivariateSequential(UnivariateSequential):

    &#34;&#34;&#34;Bivariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type BivariateTraces.

    Args:
        gen_dir (str): folder with conventional generation data
        demand (np.ndarray): demand data
        renewables (np.ndarray): renewables data
        season_length (int): number of timesteps per peak season
        n_cores (int, optional): number of cores to use for map-reduce operations
    &#34;&#34;&#34;

    _worker_class = BivariateTraces
    _area_indices = [0, 1]

    @property
    def filedirs(self):
        return [Path(self.gen_dir) / str(area) for area in self._area_indices]

    @classmethod
    def init(
        cls,
        output_dir: str,
        n_traces: int,
        n_files: int,
        gens: t.List[acg_models.Sequential],
        demand: np.ndarray,
        renewables: np.ndarray,
        season_length: int,
        n_cores: int = 4,
        burn_in: int = 100,
    ) -&gt; UnivariateSequential:
        &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and use them to instantiate a surplus model.

        Args:
            output_dir (str): output directory for trace files
            n_traces (int): Total number of traces to simulate; a trace is a sequence of at least one peak season
            n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably good enough.
            gens (acg_models.Sequential): List of sequential conventional generation instances, one per system.
            demand (np.ndarray): Demand data
            renewables (np.ndarray): Renewables data
            season_length (int): Peak season length.
            n_cores (int, optional): Number of cores to use.
            burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.

        Returns:
            BivariateSequential: Sequential surplus model


        &#34;&#34;&#34;
        for area, gen, univar_demand, univar_renewables in zip(
            cls._area_indices, gens, demand.T, renewables.T
        ):
            out_dir = Path(output_dir) / str(area)
            print(f&#34;Creating files for area {area}..&#34;)
            UnivariateSequential.init(
                output_dir=str(out_dir),
                n_traces=n_traces,
                n_files=n_files,
                gen=gen,
                demand=univar_demand,
                renewables=univar_renewables,
                season_length=season_length,
                n_cores=n_cores,
                burn_in=burn_in,
            )

        return cls(
            gen_dir=output_dir,
            demand=np.array(demand),
            renewables=np.array(renewables),
            season_length=season_length,
            n_cores=n_cores,
        )

    def create_mapred_arglist(
        self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict, policy: str
    ) -&gt; t.List[t.Dict]:
        &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
            str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.
            policy (str, optional): shortfall-sharing interconnection policy

        Returns:
            t.List[t.Any]: Named arguments list
        &#34;&#34;&#34;
        arglist = []

        # use univariate class logic to build named argument lists, whose instances are then passed as arguments to bivariate models.
        univariate_trace_pairs = []
        for filedir, demand_array, renewables_array in zip(
            self.filedirs, self.demand.T, self.renewables.T
        ):
            univar_model = UnivariateSequential(
                gen_dir=str(filedir),
                demand=demand_array,
                renewables=renewables_array,
                season_length=self.season_length,
            )

            univar_arglist = univar_model.create_mapred_arglist(
                mapper=mapper, str_map_kwargs=str_map_kwargs
            )
            # we only care for named arguments to initialise univariate surplus models
            univariate_trace_pairs.append(
                [UnivariateTraces(**named_args) for named_args, _, _ in univar_arglist]
            )

        # policy is passed here at the worker instantiation level. This is to take advantage of bivariate surplus code from the iid module. Said module implements everything for a veto policy, so it is reused. But said module does not take policy as an argument, and to overcome this in the inheriting subclass, the policy is passed at instantiation time and a reimplementation of the itc_flow method in BivariateTraces looks at the passed value to pick the correct flow equations. This is convoluted but avoids code duplication.

        # each trace here correspond to an area in the system
        for trace_x, trace_y in zip(*univariate_trace_pairs):
            bivariate_args = {
                &#34;univariate_traces&#34;: [trace_x, trace_y],
                &#34;season_length&#34;: self.season_length,
                &#34;policy&#34;: policy,
            }
            arglist.append((bivariate_args, mapper, str_map_kwargs))

        return arglist

    def map_reduce(
        self,
        mapper: t.Union[str, t.Callable],
        reducer: t.Optional[t.Callable],
        str_map_kwargs: t.Dict = {},
        policy: str = &#34;veto&#34;,
        itc_cap: float = 1000.0,
    ) -&gt; t.Any:
        &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method with that name is called on each worker instance (of class `BivariateTraces`). If a function, it must take as only argument a worker instance.
            reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, the mapper output is returned.
            str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper method when passed as a string.
            policy (str, optional): shortfall-sharing interconnection policy
            itc_cap (float, optional): Description

        Returns:
            t.Any: Description

        &#34;&#34;&#34;

        # itc_cap will be passed as an extra named argument to the mapper function, because it is an argument in all of BaseBivariateMonteCarlo methods, which are used to perform the calculations
        str_map_kwargs[&#34;itc_cap&#34;] = itc_cap

        # policy is passed as an argument at worker instantiation time to avoid code duplication. See comments on the create_mapred_arglist method.
        arglist = self.create_mapred_arglist(mapper, str_map_kwargs, policy)

        with Pool(self.n_cores) as executor:
            mapped = list(
                tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
            )

        if reducer is not None:
            return reducer(mapped)
        else:
            return mapped

    def cdf(self, x: np.ndarray, itc_cap: float = 1000.0, policy=&#34;veto&#34;):
        &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

        Args:
            x (np.ndarray): value at which to evaluate the cdf
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(
            mapper=&#34;cdf&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
            str_map_kwargs={&#34;x&#34;: x},
        )

    def lole(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
        &#34;&#34;&#34;
        offset = (
            -1e-1
        )  # this avoids numerical issues from adding up millions of numbers in the calculations
        if area in [0, 1]:
            x = np.zeros((2,), dtype=np.float32) + offset  # tiny offset
            x[1 - area] = np.Inf
            return self.season_length * self.cdf(x, itc_cap=itc_cap, policy=policy)
        elif area == -1:
            x = np.array([offset, np.Inf])
            prob = (
                self.cdf(x, itc_cap=itc_cap, policy=policy)
                + self.cdf(np.flip(x), itc_cap=itc_cap, policy=policy)
                - self.cdf(np.minimum(offset, x), itc_cap=itc_cap, policy=policy)
            )
            return self.season_length * prob
        else:
            raise ValueError(&#34;area must be in [-1,0,1]&#34;)

    def eeu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
        &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
            area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(
            mapper=&#34;eeu&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
            str_map_kwargs={&#34;area&#34;: area},
        )

    def get_surplus_df(
        self, shortfalls_only: bool = True, itc_cap: float = 1000.0, policy=&#34;veto&#34;
    ) -&gt; pd.DataFrame:
        def reducer(mapped):
            return pd.concat([df for df, n in mapped])

        return self.map_reduce(
            mapper=&#34;get_surplus_df&#34;,
            reducer=reducer,
            str_map_kwargs={&#34;shortfalls_only&#34;: shortfalls_only},
            itc_cap=itc_cap,
            policy=policy,
        )

    def __str__(self):
        return f&#34;Map-reduce based sequential surplus model using trace files in {self.gen_dir}&#34;

    def simulate_eu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season energy unserved for both areas

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

        Returns:
            np.ndarray: array with one row per peak season and one column per area
        &#34;&#34;&#34;

        def reducer(mapped):
            eu_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
            return eu_samples

        return self.map_reduce(
            mapper=&#34;simulate_eu&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
        )

    def simulate_lold(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season loss of load duration for both areas

        Args:
            itc_cap (int, optional): interconnection capacity
            policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

        Returns:
            np.ndarray: array with one row per peak season and one column per area
        &#34;&#34;&#34;

        def reducer(mapped):
            lold_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
            return lold_samples

        return self.map_reduce(
            mapper=&#34;simulate_lold&#34;,
            reducer=reducer,
            itc_cap=itc_cap,
            policy=policy,
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="riskmodels.adequacy.capacity_models.UnivariateSequential" href="#riskmodels.adequacy.capacity_models.UnivariateSequential">UnivariateSequential</a></li>
<li><a title="riskmodels.utils.adequacy_interfaces.BaseCapacityModel" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseCapacityModel">BaseCapacityModel</a></li>
<li>abc.ABC</li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.demand"><code class="name">var <span class="ident">demand</span> :Â numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.gen_dir"><code class="name">var <span class="ident">gen_dir</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.n_cores"><code class="name">var <span class="ident">n_cores</span> :Â Optional[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.renewables"><code class="name">var <span class="ident">renewables</span> :Â numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.season_length"><code class="name">var <span class="ident">season_length</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.init"><code class="name flex">
<span>def <span class="ident">init</span></span>(<span>output_dir:Â str, n_traces:Â int, n_files:Â int, gens:Â t.List[acg_models.Sequential], demand:Â np.ndarray, renewables:Â np.ndarray, season_length:Â int, n_cores:Â intÂ =Â 4, burn_in:Â intÂ =Â 100) â€‘>Â <a title="riskmodels.adequacy.capacity_models.UnivariateSequential" href="#riskmodels.adequacy.capacity_models.UnivariateSequential">UnivariateSequential</a></span>
</code></dt>
<dd>
<div class="desc"><p>Generate and persists traces of conventional generation in files, and use them to instantiate a surplus model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>output directory for trace files</dd>
<dt><strong><code>n_traces</code></strong> :&ensp;<code>int</code></dt>
<dd>Total number of traces to simulate; a trace is a sequence of at least one peak season</dd>
<dt><strong><code>n_files</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably good enough.</dd>
<dt><strong><code>gens</code></strong> :&ensp;<code>acg_models.Sequential</code></dt>
<dd>List of sequential conventional generation instances, one per system.</dd>
<dt><strong><code>demand</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Demand data</dd>
<dt><strong><code>renewables</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Renewables data</dd>
<dt><strong><code>season_length</code></strong> :&ensp;<code>int</code></dt>
<dd>Peak season length.</dd>
<dt><strong><code>n_cores</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of cores to use.</dd>
<dt><strong><code>burn_in</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Parameter passed to acg_models.Sequential.simulate_seasons.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential" href="#riskmodels.adequacy.capacity_models.BivariateSequential">BivariateSequential</a></code></dt>
<dd>Sequential surplus model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def init(
    cls,
    output_dir: str,
    n_traces: int,
    n_files: int,
    gens: t.List[acg_models.Sequential],
    demand: np.ndarray,
    renewables: np.ndarray,
    season_length: int,
    n_cores: int = 4,
    burn_in: int = 100,
) -&gt; UnivariateSequential:
    &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and use them to instantiate a surplus model.

    Args:
        output_dir (str): output directory for trace files
        n_traces (int): Total number of traces to simulate; a trace is a sequence of at least one peak season
        n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably good enough.
        gens (acg_models.Sequential): List of sequential conventional generation instances, one per system.
        demand (np.ndarray): Demand data
        renewables (np.ndarray): Renewables data
        season_length (int): Peak season length.
        n_cores (int, optional): Number of cores to use.
        burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.

    Returns:
        BivariateSequential: Sequential surplus model


    &#34;&#34;&#34;
    for area, gen, univar_demand, univar_renewables in zip(
        cls._area_indices, gens, demand.T, renewables.T
    ):
        out_dir = Path(output_dir) / str(area)
        print(f&#34;Creating files for area {area}..&#34;)
        UnivariateSequential.init(
            output_dir=str(out_dir),
            n_traces=n_traces,
            n_files=n_files,
            gen=gen,
            demand=univar_demand,
            renewables=univar_renewables,
            season_length=season_length,
            n_cores=n_cores,
            burn_in=burn_in,
        )

    return cls(
        gen_dir=output_dir,
        demand=np.array(demand),
        renewables=np.array(renewables),
        season_length=season_length,
        n_cores=n_cores,
    )</code></pre>
</details>
</dd>
</dl>
<h3>Instance variables</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.filedirs"><code class="name">var <span class="ident">filedirs</span></code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@property
def filedirs(self):
    return [Path(self.gen_dir) / str(area) for area in self._area_indices]</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.cdf"><code class="name flex">
<span>def <span class="ident">cdf</span></span>(<span>self, x:Â np.ndarray, itc_cap:Â floatÂ =Â 1000.0, policy='veto')</span>
</code></dt>
<dd>
<div class="desc"><p>Evaluates the bivariate post-interconnection capacity surplus distribution's cumulative distribution function</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>value at which to evaluate the cdf</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cdf(self, x: np.ndarray, itc_cap: float = 1000.0, policy=&#34;veto&#34;):
    &#34;&#34;&#34;Evaluates the bivariate post-interconnection capacity surplus distribution&#39;s cumulative distribution function

    Args:
        x (np.ndarray): value at which to evaluate the cdf
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, capacity shortfalls are shared according to demand proportions across areas. Shortfalls can extend from one area to another by diverting power.

    &#34;&#34;&#34;

    def reducer(mapped):
        n_traces = np.sum([n for _, n in mapped])
        return np.array([n * val for val, n in mapped]).sum() / n_traces

    return self.map_reduce(
        mapper=&#34;cdf&#34;,
        reducer=reducer,
        itc_cap=itc_cap,
        policy=policy,
        str_map_kwargs={&#34;x&#34;: x},
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.create_mapred_arglist"><code class="name flex">
<span>def <span class="ident">create_mapred_arglist</span></span>(<span>self, mapper:Â t.Union[str,Â t.Callable], str_map_kwargs:Â t.Dict, policy:Â str) â€‘>Â List[Dict[~KT,Â ~VT]]</span>
</code></dt>
<dd>
<div class="desc"><p>Create named arguments list to instantiate each worker in map reduce execution</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mapper</code></strong> :&ensp;<code>t.Union[str, t.Callable]</code></dt>
<dd>If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.</dd>
<dt><strong><code>str_map_kwargs</code></strong> :&ensp;<code>t.Tuple</code>, optional</dt>
<dd>Named arguments passed to the mapper function when it is passed as a string.</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>shortfall-sharing interconnection policy</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t.List[t.Any]</code></dt>
<dd>Named arguments list</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_mapred_arglist(
    self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict, policy: str
) -&gt; t.List[t.Dict]:
    &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

    Args:
        mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
        str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.
        policy (str, optional): shortfall-sharing interconnection policy

    Returns:
        t.List[t.Any]: Named arguments list
    &#34;&#34;&#34;
    arglist = []

    # use univariate class logic to build named argument lists, whose instances are then passed as arguments to bivariate models.
    univariate_trace_pairs = []
    for filedir, demand_array, renewables_array in zip(
        self.filedirs, self.demand.T, self.renewables.T
    ):
        univar_model = UnivariateSequential(
            gen_dir=str(filedir),
            demand=demand_array,
            renewables=renewables_array,
            season_length=self.season_length,
        )

        univar_arglist = univar_model.create_mapred_arglist(
            mapper=mapper, str_map_kwargs=str_map_kwargs
        )
        # we only care for named arguments to initialise univariate surplus models
        univariate_trace_pairs.append(
            [UnivariateTraces(**named_args) for named_args, _, _ in univar_arglist]
        )

    # policy is passed here at the worker instantiation level. This is to take advantage of bivariate surplus code from the iid module. Said module implements everything for a veto policy, so it is reused. But said module does not take policy as an argument, and to overcome this in the inheriting subclass, the policy is passed at instantiation time and a reimplementation of the itc_flow method in BivariateTraces looks at the passed value to pick the correct flow equations. This is convoluted but avoids code duplication.

    # each trace here correspond to an area in the system
    for trace_x, trace_y in zip(*univariate_trace_pairs):
        bivariate_args = {
            &#34;univariate_traces&#34;: [trace_x, trace_y],
            &#34;season_length&#34;: self.season_length,
            &#34;policy&#34;: policy,
        }
        arglist.append((bivariate_args, mapper, str_map_kwargs))

    return arglist</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.eeu"><code class="name flex">
<span>def <span class="ident">eeu</span></span>(<span>self, itc_cap:Â floatÂ =Â 1000.0, policy='veto', area:Â intÂ =Â 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the post-interconnection expected energy unserved.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.</dd>
<dt><strong><code>area</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Area for which to evaluate eeu; if area=-1, systemwide eeu is returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eeu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
    &#34;&#34;&#34;Computes the post-interconnection expected energy unserved.

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
        area (int, optional): Area for which to evaluate eeu; if area=-1, systemwide eeu is returned
    &#34;&#34;&#34;

    def reducer(mapped):
        n_traces = np.sum([n for _, n in mapped])
        return np.array([n * val for val, n in mapped]).sum() / n_traces

    return self.map_reduce(
        mapper=&#34;eeu&#34;,
        reducer=reducer,
        itc_cap=itc_cap,
        policy=policy,
        str_map_kwargs={&#34;area&#34;: area},
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.lole"><code class="name flex">
<span>def <span class="ident">lole</span></span>(<span>self, itc_cap:Â floatÂ =Â 1000.0, policy='veto', area:Â intÂ =Â 0)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the post-interconnection loss of load expectation.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.</dd>
<dt><strong><code>area</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Area for which to evaluate LOLE; if area=-1, system-wide lole is returned</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lole(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;, area: int = 0):
    &#34;&#34;&#34;Computes the post-interconnection loss of load expectation.

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.
        area (int, optional): Area for which to evaluate LOLE; if area=-1, system-wide lole is returned
    &#34;&#34;&#34;
    offset = (
        -1e-1
    )  # this avoids numerical issues from adding up millions of numbers in the calculations
    if area in [0, 1]:
        x = np.zeros((2,), dtype=np.float32) + offset  # tiny offset
        x[1 - area] = np.Inf
        return self.season_length * self.cdf(x, itc_cap=itc_cap, policy=policy)
    elif area == -1:
        x = np.array([offset, np.Inf])
        prob = (
            self.cdf(x, itc_cap=itc_cap, policy=policy)
            + self.cdf(np.flip(x), itc_cap=itc_cap, policy=policy)
            - self.cdf(np.minimum(offset, x), itc_cap=itc_cap, policy=policy)
        )
        return self.season_length * prob
    else:
        raise ValueError(&#34;area must be in [-1,0,1]&#34;)</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.map_reduce"><code class="name flex">
<span>def <span class="ident">map_reduce</span></span>(<span>self, mapper:Â t.Union[str,Â t.Callable], reducer:Â t.Optional[t.Callable], str_map_kwargs:Â t.DictÂ =Â {}, policy:Â strÂ =Â 'veto', itc_cap:Â floatÂ =Â 1000.0) â€‘>Â Any</span>
</code></dt>
<dd>
<div class="desc"><p>Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mapper</code></strong> :&ensp;<code>t.Union[str, t.Callable]</code></dt>
<dd>If a string, the method with that name is called on each worker instance (of class <code>BivariateTraces</code>). If a function, it must take as only argument a worker instance.</dd>
<dt><strong><code>reducer</code></strong> :&ensp;<code>t.Optional[t.Callable]</code></dt>
<dd>This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, the mapper output is returned.</dd>
<dt><strong><code>str_map_kwargs</code></strong> :&ensp;<code>t.Dict</code>, optional</dt>
<dd>Named arguments passed to the mapper method when passed as a string.</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>shortfall-sharing interconnection policy</dd>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Description</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t.Any</code></dt>
<dd>Description</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_reduce(
    self,
    mapper: t.Union[str, t.Callable],
    reducer: t.Optional[t.Callable],
    str_map_kwargs: t.Dict = {},
    policy: str = &#34;veto&#34;,
    itc_cap: float = 1000.0,
) -&gt; t.Any:
    &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

    Args:
        mapper (t.Union[str, t.Callable]): If a string, the method with that name is called on each worker instance (of class `BivariateTraces`). If a function, it must take as only argument a worker instance.
        reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, the mapper output is returned.
        str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper method when passed as a string.
        policy (str, optional): shortfall-sharing interconnection policy
        itc_cap (float, optional): Description

    Returns:
        t.Any: Description

    &#34;&#34;&#34;

    # itc_cap will be passed as an extra named argument to the mapper function, because it is an argument in all of BaseBivariateMonteCarlo methods, which are used to perform the calculations
    str_map_kwargs[&#34;itc_cap&#34;] = itc_cap

    # policy is passed as an argument at worker instantiation time to avoid code duplication. See comments on the create_mapred_arglist method.
    arglist = self.create_mapred_arglist(mapper, str_map_kwargs, policy)

    with Pool(self.n_cores) as executor:
        mapped = list(
            tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
        )

    if reducer is not None:
        return reducer(mapped)
    else:
        return mapped</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.simulate_eu"><code class="name flex">
<span>def <span class="ident">simulate_eu</span></span>(<span>self, itc_cap:Â floatÂ =Â 1000.0, policy='veto') â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Simulates per-peak-season energy unserved for both areas</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>array with one row per peak season and one column per area</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_eu(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
    &#34;&#34;&#34;Simulates per-peak-season energy unserved for both areas

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

    Returns:
        np.ndarray: array with one row per peak season and one column per area
    &#34;&#34;&#34;

    def reducer(mapped):
        eu_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
        return eu_samples

    return self.map_reduce(
        mapper=&#34;simulate_eu&#34;,
        reducer=reducer,
        itc_cap=itc_cap,
        policy=policy,
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.BivariateSequential.simulate_lold"><code class="name flex">
<span>def <span class="ident">simulate_lold</span></span>(<span>self, itc_cap:Â floatÂ =Â 1000.0, policy='veto') â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Simulates per-peak-season loss of load duration for both areas</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>itc_cap</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>interconnection capacity</dd>
<dt><strong><code>policy</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>one of 'veto' or 'share'; in a 'veto' policy, areas only export spare available capacity, while in a 'share' policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>array with one row per peak season and one column per area</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_lold(self, itc_cap: float = 1000.0, policy=&#34;veto&#34;) -&gt; np.ndarray:
    &#34;&#34;&#34;Simulates per-peak-season loss of load duration for both areas

    Args:
        itc_cap (int, optional): interconnection capacity
        policy (str, optional): one of &#39;veto&#39; or &#39;share&#39;; in a &#39;veto&#39; policy, areas only export spare available capacity, while in a &#39;share&#39; policy, exports are market-driven, i.e., by power scarcity at both areas. Shortfalls can extend from one area to another by diverting power.

    Returns:
        np.ndarray: array with one row per peak season and one column per area
    &#34;&#34;&#34;

    def reducer(mapped):
        lold_samples = np.concatenate([sample for sample, _ in mapped], axis=0)
        return lold_samples

    return self.map_reduce(
        mapper=&#34;simulate_lold&#34;,
        reducer=reducer,
        itc_cap=itc_cap,
        policy=policy,
    )</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="riskmodels.adequacy.capacity_models.UnivariateSequential" href="#riskmodels.adequacy.capacity_models.UnivariateSequential">UnivariateSequential</a></b></code>:
<ul class="hlist">
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.execute_map" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.execute_map">execute_map</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.get_surplus_df" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.get_surplus_df">get_surplus_df</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential"><code class="flex name class">
<span>class <span class="ident">UnivariateSequential</span></span>
<span>(</span><span>**data:Â Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Univariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type UnivariateTraces.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>gen_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>folder with conventional generation data</dd>
<dt><strong><code>demand</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>demand data</dd>
<dt><strong><code>renewables</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>renewables data</dd>
<dt><strong><code>season_length</code></strong> :&ensp;<code>int</code></dt>
<dd>number of timesteps per peak season</dd>
<dt><strong><code>n_cores</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>number of cores to use for map-reduce operations</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class UnivariateSequential(BaseCapacityModel, BasePydanticModel):

    &#34;&#34;&#34;Univariate model for capacity surplus using a sequential available conventional generation model, implementing Monte Carlo evaluations through map-reduce patterns. Worker instances are of type UnivariateTraces.

    Args:
        gen_dir (str): folder with conventional generation data
        demand (np.ndarray): demand data
        renewables (np.ndarray): renewables data
        season_length (int): number of timesteps per peak season
        n_cores (int, optional): number of cores to use for map-reduce operations

    &#34;&#34;&#34;

    gen_dir: str
    demand: np.ndarray
    renewables: np.ndarray
    season_length: int
    n_cores: t.Optional[int] = 2

    _worker_class = UnivariateTraces

    class Config:
        arbitrary_types_allowed = True

    @classmethod
    def _persist_gen_traces(
        cls, args: t.Tuple[acg_models.Sequential, t.Dict, Path, int]
    ) -&gt; None:
        &#34;&#34;&#34;Persists a sequence of traces according to specified arguments as a numpy file

        Args:
            args (t.Tuple[acg_models.Sequential, t.Dict, Path]): trace generation parameters
        &#34;&#34;&#34;
        gen, call_kwargs, filename = args
        traces = gen.simulate_seasons(**call_kwargs)
        np.save(filename, traces)

    @classmethod
    def init(
        cls,
        output_dir: str,
        n_traces: int,
        n_files: int,
        gen: acg_models.Sequential,
        demand: np.ndarray,
        renewables: np.ndarray,
        season_length: int,
        n_cores: int = 4,
        burn_in: int = 100,
        seed: int = None,
    ) -&gt; BaseCapacityModel:
        &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and uses them to instantiate a surplus model. Returns a surplus model ready to perform computations with the generated files.

        Args:
            output_dir (str): Output directory for trace files
            n_traces (int): Total number of season traces to simulate
            n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably optimal.
            gen (acg_models.Sequential): Sequential conventional generation instance.
            demand (np.ndarray): Demand data
            renewables (np.ndarray): renewable generation data
            season_length (int): Peak season length.
            n_cores (int, optional): Number of cores to use.
            burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.
            seed (int, optional): Random seed passed to C backend. If not passed, output file paths are hashed to obtained it; this is because different seeds are needed for each file, otherwise traces are identical across files.

        No Longer Returned:
            UnivariateSequential: Sequential surplus model

        &#34;&#34;&#34;

        # create dir if it doesn&#39;t exist
        Path(output_dir).mkdir(parents=True, exist_ok=True)

        if len(demand) != len(renewables):
            raise ValueError(&#34;demand and renewables must have the same length.&#34;)

        trace_length = len(demand)

        if trace_length % season_length != 0:
            raise ValueError(&#34;trace_length must be divisible by season_length.&#34;)

        if n_traces &lt;= 0 or not isinstance(n_traces, int):
            raise ValueError(&#34;n_traces must be a positive integer&#34;)

        if n_files &lt;= 0 or not isinstance(n_files, int):
            raise ValueError(&#34;n_files must be a positive integer&#34;)

        # compute file size (in terms of number of traces)
        file_sizes = [int(n_traces / n_files) for k in range(n_files)]
        file_sizes[-1] += n_traces - sum(file_sizes)

        # create argument list for multithreaded execution
        arglist = []
        seasons_per_trace = int(trace_length / season_length)
        for idx, file_size in enumerate(file_sizes):
            output_path = Path(output_dir) / str(idx)
            file_seed = (
                seed + idx
                if seed is not None
                else abs(adler32(str(output_path).encode(&#34;utf-8&#34;))) % (1024 * 1024)
            )
            call_kwargs = {
                &#34;size&#34;: file_size,
                &#34;season_length&#34;: season_length,
                &#34;seasons_per_trace&#34;: seasons_per_trace,
                &#34;burn_in&#34;: burn_in,
                &#34;seed&#34;: file_seed,
            }
            arglist.append((gen, call_kwargs, output_path))

        # create files in parallel
        with Pool(n_cores) as executor:
            jobs = list(
                tqdm(
                    executor.imap(cls._persist_gen_traces, arglist), total=len(arglist)
                )
            )

        return cls(
            gen_dir=output_dir,
            demand=np.array(demand),
            renewables=np.array(renewables),
            season_length=season_length,
            n_cores=n_cores,
        )

    def create_mapred_arglist(
        self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict
    ) -&gt; t.List[t.Dict]:
        &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
            str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.

        Returns:
            t.List[t.Any]: Named arguments list
        &#34;&#34;&#34;
        arglist = []
        # create arglist for parallel execution
        for file in Path(self.gen_dir).iterdir():
            kwargs = {
                &#34;gen_filepath&#34;: str(file),
                &#34;demand&#34;: self.demand,
                &#34;renewables&#34;: self.renewables,
                &#34;season_length&#34;: self.season_length,
            }
            arglist.append((kwargs, mapper, str_map_kwargs))

        return arglist

    @classmethod
    def execute_map(
        cls, call_args: t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]
    ) -&gt; t.Tuple[t.Any, int]:
        &#34;&#34;&#34;Instantiate a worker with the passed arguments and execute mapper function on it. Returns both the result of the mapper function and the number of traces processed; the latter is helpful when results from the mappers are aggregated, e.g. global averaging.

        Args:
            call_args (t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]): A triplet with named arguments to instantiate the workers, the function to call on instantiated workers as a string or callable object, and additional unnamed arguments passed to the mapper if given as a string.

        Returns:
            t.Tuple[t.Any, int]: tuple with mapper output and the number of traces processed

        &#34;&#34;&#34;
        worker_kwargs, map_func, str_map_kwargs = call_args
        worker = cls._worker_class(**worker_kwargs)
        n_traces = worker.n_traces
        if isinstance(map_func, str):
            return getattr(worker, map_func)(**str_map_kwargs), n_traces
        elif isinstance(map_func, t.Callable):
            return map_func(worker), n_traces
        else:
            raise ValueError(&#34;map_func must be a string or a function.&#34;)

    def map_reduce(
        self,
        mapper: t.Union[str, t.Callable],
        reducer: t.Optional[t.Callable],
        str_map_kwargs: t.Dict = {},
    ) -&gt; t.Any:
        &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

        Args:
            mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance (of class UnivariateTraces). If a function, it must take as only argument a worker instance.
            reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, no reducer is applied.
            str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper function when passed as a string.

        Returns:
            t.Any: Map-reduce output

        &#34;&#34;&#34;

        arglist = self.create_mapred_arglist(mapper, str_map_kwargs)

        with Pool(self.n_cores) as executor:
            mapped = list(
                tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
            )

        if reducer is not None:
            return reducer(mapped)
        else:
            return mapped

    def cdf(self, x: float) -&gt; float:
        &#34;&#34;&#34;Computes the surplus&#39; cumulative distribution function (CDF) evaluated at a point

        Args:
            x (float): Point at which to evaluate the CDF

        Returns:
            float: CDF estimate
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(mapper=&#34;cdf&#34;, reducer=reducer, str_map_kwargs={&#34;x&#34;: x})

    def simulate(self):
        raise NotImplementedError(
            &#34;This class does not implement a simulate() method. Use get_surplus_df() to get the trace of shortfalls or the full trace of surplus values; alternatively see methods simulate_eu() and simulate_lold().&#34;
        )

    def lole(self) -&gt; float:
        &#34;&#34;&#34;Computes the loss of load expectation

        Returns:
            float: lole estimate
        &#34;&#34;&#34;
        return self.season_length * self.cdf(
            x=-1e-1
        )  # tiny offset to avoid issues with numerical rounding errors from adding millions of numbers together

    def eeu(self):
        &#34;&#34;&#34;Computes the expected energy unserved

        Returns:
            float: eeu estimate
        &#34;&#34;&#34;

        def reducer(mapped):
            n_traces = np.sum([n for _, n in mapped])
            return np.array([n * val for val, n in mapped]).sum() / n_traces

        return self.map_reduce(mapper=&#34;eeu&#34;, reducer=reducer)

    def simulate_eu(self) -&gt; np.ndarray:
        &#34;&#34;&#34;Simulates per-peak-season energy userved

        Returns:
            np.ndarray: array with one entry per peak season
        &#34;&#34;&#34;

        def reducer(mapped):
            eu_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
            return eu_samples

        return self.map_reduce(mapper=&#34;simulate_eu&#34;, reducer=reducer)

    def simulate_lold(self):
        &#34;&#34;&#34;Simulates per-peak-season loss of load duration

        Returns:
            np.ndarray: array with one entry per peak season
        &#34;&#34;&#34;

        def reducer(mapped):
            lold_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
            return lold_samples

        return self.map_reduce(mapper=&#34;simulate_lold&#34;, reducer=reducer)

    def get_surplus_df(self, shortfalls_only: bool = True) -&gt; pd.DataFrame:
        &#34;&#34;&#34;Returns a data frame with time occurrence information of observed surplus values and shortfalls.

        Args:
            shortfalls_only (bool, optional): If True, only shortfall rows are returned

        Returns:
            pd.DataFrame: A data frame with the surplus values, a &#39;season_time&#39; column with the within-season time of occurrence (0,1,...,season_length-1), a &#39;file_id&#39; column that indicates which file was used to compute the value, and a &#39;season&#39; column to indicate which season the value was observed in.

        &#34;&#34;&#34;

        def reducer(mapped):
            # compute global season number when merging results from different files (each with their own season numbering)
            trace_length = len(self.demand)
            seasons_per_trace = trace_length / self.season_length
            if seasons_per_trace != int(seasons_per_trace):
                raise ValueError(
                    f&#34;trace length ({trace_length}) is not a multiple of season length ({season_length})&#34;
                )
            seasons_per_trace = int(seasons_per_trace)
            past_seasons = 0
            for df, n_traces in mapped:
                df[&#34;season&#34;] += past_seasons
                past_seasons += n_traces * seasons_per_trace
            return pd.concat([df for df, n in mapped])

        return self.map_reduce(
            mapper=&#34;get_surplus_df&#34;,
            reducer=reducer,
            str_map_kwargs={&#34;shortfalls_only&#34;: shortfalls_only},
        )

    def __str__(self):
        return f&#34;Map-reduce based sequential surplus model using trace files in {self.gen_dir}&#34;</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="riskmodels.utils.adequacy_interfaces.BaseCapacityModel" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseCapacityModel">BaseCapacityModel</a></li>
<li>abc.ABC</li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="riskmodels.adequacy.capacity_models.BivariateSequential" href="#riskmodels.adequacy.capacity_models.BivariateSequential">BivariateSequential</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.Config"><code class="name">var <span class="ident">Config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.demand"><code class="name">var <span class="ident">demand</span> :Â numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.gen_dir"><code class="name">var <span class="ident">gen_dir</span> :Â str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.n_cores"><code class="name">var <span class="ident">n_cores</span> :Â Optional[int]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.renewables"><code class="name">var <span class="ident">renewables</span> :Â numpy.ndarray</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.season_length"><code class="name">var <span class="ident">season_length</span> :Â int</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.execute_map"><code class="name flex">
<span>def <span class="ident">execute_map</span></span>(<span>call_args:Â t.Tuple[t.Dict,Â t.Union[str,Â t.Callable],Â t.Tuple]) â€‘>Â Tuple[Any,Â int]</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate a worker with the passed arguments and execute mapper function on it. Returns both the result of the mapper function and the number of traces processed; the latter is helpful when results from the mappers are aggregated, e.g. global averaging.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>call_args</code></strong> :&ensp;<code>t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]</code></dt>
<dd>A triplet with named arguments to instantiate the workers, the function to call on instantiated workers as a string or callable object, and additional unnamed arguments passed to the mapper if given as a string.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t.Tuple[t.Any, int]</code></dt>
<dd>tuple with mapper output and the number of traces processed</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def execute_map(
    cls, call_args: t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]
) -&gt; t.Tuple[t.Any, int]:
    &#34;&#34;&#34;Instantiate a worker with the passed arguments and execute mapper function on it. Returns both the result of the mapper function and the number of traces processed; the latter is helpful when results from the mappers are aggregated, e.g. global averaging.

    Args:
        call_args (t.Tuple[t.Dict, t.Union[str, t.Callable], t.Tuple]): A triplet with named arguments to instantiate the workers, the function to call on instantiated workers as a string or callable object, and additional unnamed arguments passed to the mapper if given as a string.

    Returns:
        t.Tuple[t.Any, int]: tuple with mapper output and the number of traces processed

    &#34;&#34;&#34;
    worker_kwargs, map_func, str_map_kwargs = call_args
    worker = cls._worker_class(**worker_kwargs)
    n_traces = worker.n_traces
    if isinstance(map_func, str):
        return getattr(worker, map_func)(**str_map_kwargs), n_traces
    elif isinstance(map_func, t.Callable):
        return map_func(worker), n_traces
    else:
        raise ValueError(&#34;map_func must be a string or a function.&#34;)</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.init"><code class="name flex">
<span>def <span class="ident">init</span></span>(<span>output_dir:Â str, n_traces:Â int, n_files:Â int, gen:Â acg_models.Sequential, demand:Â np.ndarray, renewables:Â np.ndarray, season_length:Â int, n_cores:Â intÂ =Â 4, burn_in:Â intÂ =Â 100, seed:Â intÂ =Â None) â€‘>Â <a title="riskmodels.utils.adequacy_interfaces.BaseCapacityModel" href="../utils/adequacy_interfaces.html#riskmodels.utils.adequacy_interfaces.BaseCapacityModel">BaseCapacityModel</a></span>
</code></dt>
<dd>
<div class="desc"><p>Generate and persists traces of conventional generation in files, and uses them to instantiate a surplus model. Returns a surplus model ready to perform computations with the generated files.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>output_dir</code></strong> :&ensp;<code>str</code></dt>
<dd>Output directory for trace files</dd>
<dt><strong><code>n_traces</code></strong> :&ensp;<code>int</code></dt>
<dd>Total number of season traces to simulate</dd>
<dt><strong><code>n_files</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably optimal.</dd>
<dt><strong><code>gen</code></strong> :&ensp;<code>acg_models.Sequential</code></dt>
<dd>Sequential conventional generation instance.</dd>
<dt><strong><code>demand</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Demand data</dd>
<dt><strong><code>renewables</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>renewable generation data</dd>
<dt><strong><code>season_length</code></strong> :&ensp;<code>int</code></dt>
<dd>Peak season length.</dd>
<dt><strong><code>n_cores</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of cores to use.</dd>
<dt><strong><code>burn_in</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Parameter passed to acg_models.Sequential.simulate_seasons.</dd>
<dt><strong><code>seed</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Random seed passed to C backend. If not passed, output file paths are hashed to obtained it; this is because different seeds are needed for each file, otherwise traces are identical across files.</dd>
</dl>
<p>No Longer Returned:
UnivariateSequential: Sequential surplus model</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def init(
    cls,
    output_dir: str,
    n_traces: int,
    n_files: int,
    gen: acg_models.Sequential,
    demand: np.ndarray,
    renewables: np.ndarray,
    season_length: int,
    n_cores: int = 4,
    burn_in: int = 100,
    seed: int = None,
) -&gt; BaseCapacityModel:
    &#34;&#34;&#34;Generate and persists traces of conventional generation in files, and uses them to instantiate a surplus model. Returns a surplus model ready to perform computations with the generated files.

    Args:
        output_dir (str): Output directory for trace files
        n_traces (int): Total number of season traces to simulate
        n_files (int): Number of files to create. Making this a multiple of the available number of cores and ensuring that each file is on the order of 500 MB (~ 125 million floats) is probably optimal.
        gen (acg_models.Sequential): Sequential conventional generation instance.
        demand (np.ndarray): Demand data
        renewables (np.ndarray): renewable generation data
        season_length (int): Peak season length.
        n_cores (int, optional): Number of cores to use.
        burn_in (int, optional): Parameter passed to acg_models.Sequential.simulate_seasons.
        seed (int, optional): Random seed passed to C backend. If not passed, output file paths are hashed to obtained it; this is because different seeds are needed for each file, otherwise traces are identical across files.

    No Longer Returned:
        UnivariateSequential: Sequential surplus model

    &#34;&#34;&#34;

    # create dir if it doesn&#39;t exist
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    if len(demand) != len(renewables):
        raise ValueError(&#34;demand and renewables must have the same length.&#34;)

    trace_length = len(demand)

    if trace_length % season_length != 0:
        raise ValueError(&#34;trace_length must be divisible by season_length.&#34;)

    if n_traces &lt;= 0 or not isinstance(n_traces, int):
        raise ValueError(&#34;n_traces must be a positive integer&#34;)

    if n_files &lt;= 0 or not isinstance(n_files, int):
        raise ValueError(&#34;n_files must be a positive integer&#34;)

    # compute file size (in terms of number of traces)
    file_sizes = [int(n_traces / n_files) for k in range(n_files)]
    file_sizes[-1] += n_traces - sum(file_sizes)

    # create argument list for multithreaded execution
    arglist = []
    seasons_per_trace = int(trace_length / season_length)
    for idx, file_size in enumerate(file_sizes):
        output_path = Path(output_dir) / str(idx)
        file_seed = (
            seed + idx
            if seed is not None
            else abs(adler32(str(output_path).encode(&#34;utf-8&#34;))) % (1024 * 1024)
        )
        call_kwargs = {
            &#34;size&#34;: file_size,
            &#34;season_length&#34;: season_length,
            &#34;seasons_per_trace&#34;: seasons_per_trace,
            &#34;burn_in&#34;: burn_in,
            &#34;seed&#34;: file_seed,
        }
        arglist.append((gen, call_kwargs, output_path))

    # create files in parallel
    with Pool(n_cores) as executor:
        jobs = list(
            tqdm(
                executor.imap(cls._persist_gen_traces, arglist), total=len(arglist)
            )
        )

    return cls(
        gen_dir=output_dir,
        demand=np.array(demand),
        renewables=np.array(renewables),
        season_length=season_length,
        n_cores=n_cores,
    )</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.cdf"><code class="name flex">
<span>def <span class="ident">cdf</span></span>(<span>self, x:Â float) â€‘>Â float</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the surplus' cumulative distribution function (CDF) evaluated at a point</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>float</code></dt>
<dd>Point at which to evaluate the CDF</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>CDF estimate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def cdf(self, x: float) -&gt; float:
    &#34;&#34;&#34;Computes the surplus&#39; cumulative distribution function (CDF) evaluated at a point

    Args:
        x (float): Point at which to evaluate the CDF

    Returns:
        float: CDF estimate
    &#34;&#34;&#34;

    def reducer(mapped):
        n_traces = np.sum([n for _, n in mapped])
        return np.array([n * val for val, n in mapped]).sum() / n_traces

    return self.map_reduce(mapper=&#34;cdf&#34;, reducer=reducer, str_map_kwargs={&#34;x&#34;: x})</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.create_mapred_arglist"><code class="name flex">
<span>def <span class="ident">create_mapred_arglist</span></span>(<span>self, mapper:Â t.Union[str,Â t.Callable], str_map_kwargs:Â t.Dict) â€‘>Â List[Dict[~KT,Â ~VT]]</span>
</code></dt>
<dd>
<div class="desc"><p>Create named arguments list to instantiate each worker in map reduce execution</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mapper</code></strong> :&ensp;<code>t.Union[str, t.Callable]</code></dt>
<dd>If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.</dd>
<dt><strong><code>str_map_kwargs</code></strong> :&ensp;<code>t.Tuple</code>, optional</dt>
<dd>Named arguments passed to the mapper function when it is passed as a string.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t.List[t.Any]</code></dt>
<dd>Named arguments list</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_mapred_arglist(
    self, mapper: t.Union[str, t.Callable], str_map_kwargs: t.Dict
) -&gt; t.List[t.Dict]:
    &#34;&#34;&#34;Create named arguments list to instantiate each worker in map reduce execution

    Args:
        mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance. If a function, it must take as only argument a worker instance.
        str_map_kwargs (t.Tuple, optional): Named arguments passed to the mapper function when it is passed as a string.

    Returns:
        t.List[t.Any]: Named arguments list
    &#34;&#34;&#34;
    arglist = []
    # create arglist for parallel execution
    for file in Path(self.gen_dir).iterdir():
        kwargs = {
            &#34;gen_filepath&#34;: str(file),
            &#34;demand&#34;: self.demand,
            &#34;renewables&#34;: self.renewables,
            &#34;season_length&#34;: self.season_length,
        }
        arglist.append((kwargs, mapper, str_map_kwargs))

    return arglist</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.eeu"><code class="name flex">
<span>def <span class="ident">eeu</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the expected energy unserved</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>eeu estimate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def eeu(self):
    &#34;&#34;&#34;Computes the expected energy unserved

    Returns:
        float: eeu estimate
    &#34;&#34;&#34;

    def reducer(mapped):
        n_traces = np.sum([n for _, n in mapped])
        return np.array([n * val for val, n in mapped]).sum() / n_traces

    return self.map_reduce(mapper=&#34;eeu&#34;, reducer=reducer)</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.get_surplus_df"><code class="name flex">
<span>def <span class="ident">get_surplus_df</span></span>(<span>self, shortfalls_only:Â boolÂ =Â True) â€‘>Â pandas.core.frame.DataFrame</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a data frame with time occurrence information of observed surplus values and shortfalls.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>shortfalls_only</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, only shortfall rows are returned</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pd.DataFrame</code></dt>
<dd>A data frame with the surplus values, a 'season_time' column with the within-season time of occurrence (0,1,&hellip;,season_length-1), a 'file_id' column that indicates which file was used to compute the value, and a 'season' column to indicate which season the value was observed in.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_surplus_df(self, shortfalls_only: bool = True) -&gt; pd.DataFrame:
    &#34;&#34;&#34;Returns a data frame with time occurrence information of observed surplus values and shortfalls.

    Args:
        shortfalls_only (bool, optional): If True, only shortfall rows are returned

    Returns:
        pd.DataFrame: A data frame with the surplus values, a &#39;season_time&#39; column with the within-season time of occurrence (0,1,...,season_length-1), a &#39;file_id&#39; column that indicates which file was used to compute the value, and a &#39;season&#39; column to indicate which season the value was observed in.

    &#34;&#34;&#34;

    def reducer(mapped):
        # compute global season number when merging results from different files (each with their own season numbering)
        trace_length = len(self.demand)
        seasons_per_trace = trace_length / self.season_length
        if seasons_per_trace != int(seasons_per_trace):
            raise ValueError(
                f&#34;trace length ({trace_length}) is not a multiple of season length ({season_length})&#34;
            )
        seasons_per_trace = int(seasons_per_trace)
        past_seasons = 0
        for df, n_traces in mapped:
            df[&#34;season&#34;] += past_seasons
            past_seasons += n_traces * seasons_per_trace
        return pd.concat([df for df, n in mapped])

    return self.map_reduce(
        mapper=&#34;get_surplus_df&#34;,
        reducer=reducer,
        str_map_kwargs={&#34;shortfalls_only&#34;: shortfalls_only},
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.lole"><code class="name flex">
<span>def <span class="ident">lole</span></span>(<span>self) â€‘>Â float</span>
</code></dt>
<dd>
<div class="desc"><p>Computes the loss of load expectation</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>float</code></dt>
<dd>lole estimate</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def lole(self) -&gt; float:
    &#34;&#34;&#34;Computes the loss of load expectation

    Returns:
        float: lole estimate
    &#34;&#34;&#34;
    return self.season_length * self.cdf(
        x=-1e-1
    )  # tiny offset to avoid issues with numerical rounding errors from adding millions of numbers together</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.map_reduce"><code class="name flex">
<span>def <span class="ident">map_reduce</span></span>(<span>self, mapper:Â t.Union[str,Â t.Callable], reducer:Â t.Optional[t.Callable], str_map_kwargs:Â t.DictÂ =Â {}) â€‘>Â Any</span>
</code></dt>
<dd>
<div class="desc"><p>Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>mapper</code></strong> :&ensp;<code>t.Union[str, t.Callable]</code></dt>
<dd>If a string, the method of that name is called on each worker instance (of class UnivariateTraces). If a function, it must take as only argument a worker instance.</dd>
<dt><strong><code>reducer</code></strong> :&ensp;<code>t.Optional[t.Callable]</code></dt>
<dd>This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, no reducer is applied.</dd>
<dt><strong><code>str_map_kwargs</code></strong> :&ensp;<code>t.Dict</code>, optional</dt>
<dd>Named arguments passed to the mapper function when passed as a string.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>t.Any</code></dt>
<dd>Map-reduce output</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def map_reduce(
    self,
    mapper: t.Union[str, t.Callable],
    reducer: t.Optional[t.Callable],
    str_map_kwargs: t.Dict = {},
) -&gt; t.Any:
    &#34;&#34;&#34;Performs map-reduce processing operations on each persisted generation trace file, given mapper and reducer functions

    Args:
        mapper (t.Union[str, t.Callable]): If a string, the method of that name is called on each worker instance (of class UnivariateTraces). If a function, it must take as only argument a worker instance.
        reducer (t.Optional[t.Callable]): This function must take as input a list where each entry is a tuple with the mapper output and the number of traces processed by the mapper, in that order. If None, no reducer is applied.
        str_map_kwargs (t.Dict, optional): Named arguments passed to the mapper function when passed as a string.

    Returns:
        t.Any: Map-reduce output

    &#34;&#34;&#34;

    arglist = self.create_mapred_arglist(mapper, str_map_kwargs)

    with Pool(self.n_cores) as executor:
        mapped = list(
            tqdm(executor.imap(self.execute_map, arglist), total=len(arglist))
        )

    if reducer is not None:
        return reducer(mapped)
    else:
        return mapped</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate"><code class="name flex">
<span>def <span class="ident">simulate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate(self):
    raise NotImplementedError(
        &#34;This class does not implement a simulate() method. Use get_surplus_df() to get the trace of shortfalls or the full trace of surplus values; alternatively see methods simulate_eu() and simulate_lold().&#34;
    )</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_eu"><code class="name flex">
<span>def <span class="ident">simulate_eu</span></span>(<span>self) â€‘>Â numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Simulates per-peak-season energy userved</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>array with one entry per peak season</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_eu(self) -&gt; np.ndarray:
    &#34;&#34;&#34;Simulates per-peak-season energy userved

    Returns:
        np.ndarray: array with one entry per peak season
    &#34;&#34;&#34;

    def reducer(mapped):
        eu_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
        return eu_samples

    return self.map_reduce(mapper=&#34;simulate_eu&#34;, reducer=reducer)</code></pre>
</details>
</dd>
<dt id="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_lold"><code class="name flex">
<span>def <span class="ident">simulate_lold</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Simulates per-peak-season loss of load duration</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>array with one entry per peak season</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def simulate_lold(self):
    &#34;&#34;&#34;Simulates per-peak-season loss of load duration

    Returns:
        np.ndarray: array with one entry per peak season
    &#34;&#34;&#34;

    def reducer(mapped):
        lold_samples = np.concatenate([samples for samples, _ in mapped], axis=0)
        return lold_samples

    return self.map_reduce(mapper=&#34;simulate_lold&#34;, reducer=reducer)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="riskmodels.adequacy" href="index.html">riskmodels.adequacy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical">BivariateNSEmpirical</a></code></h4>
<ul class="">
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.cdf" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.cdf">cdf</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.eeu" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.eeu">eeu</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.get_pointwise_risk" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.get_pointwise_risk">get_pointwise_risk</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.lole" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.lole">lole</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate">simulate</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_conditional" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_conditional">simulate_conditional</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_region" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.simulate_region">simulate_region</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.swap_axes" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.swap_axes">swap_axes</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSEmpirical.system_lolp" href="#riskmodels.adequacy.capacity_models.BivariateNSEmpirical.system_lolp">system_lolp</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo">BivariateNSMonteCarlo</a></code></h4>
<ul class="">
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.Config" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.Config">Config</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.gen_distribution" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.gen_distribution">gen_distribution</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.get_pre_itc_sample" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.get_pre_itc_sample">get_pre_itc_sample</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.net_demand" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.net_demand">net_demand</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.size" href="#riskmodels.adequacy.capacity_models.BivariateNSMonteCarlo.size">size</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential" href="#riskmodels.adequacy.capacity_models.BivariateSequential">BivariateSequential</a></code></h4>
<ul class="">
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.cdf" href="#riskmodels.adequacy.capacity_models.BivariateSequential.cdf">cdf</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.create_mapred_arglist" href="#riskmodels.adequacy.capacity_models.BivariateSequential.create_mapred_arglist">create_mapred_arglist</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.demand" href="#riskmodels.adequacy.capacity_models.BivariateSequential.demand">demand</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.eeu" href="#riskmodels.adequacy.capacity_models.BivariateSequential.eeu">eeu</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.filedirs" href="#riskmodels.adequacy.capacity_models.BivariateSequential.filedirs">filedirs</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.gen_dir" href="#riskmodels.adequacy.capacity_models.BivariateSequential.gen_dir">gen_dir</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.init" href="#riskmodels.adequacy.capacity_models.BivariateSequential.init">init</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.lole" href="#riskmodels.adequacy.capacity_models.BivariateSequential.lole">lole</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.map_reduce" href="#riskmodels.adequacy.capacity_models.BivariateSequential.map_reduce">map_reduce</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.n_cores" href="#riskmodels.adequacy.capacity_models.BivariateSequential.n_cores">n_cores</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.renewables" href="#riskmodels.adequacy.capacity_models.BivariateSequential.renewables">renewables</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.season_length" href="#riskmodels.adequacy.capacity_models.BivariateSequential.season_length">season_length</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.simulate_eu" href="#riskmodels.adequacy.capacity_models.BivariateSequential.simulate_eu">simulate_eu</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.BivariateSequential.simulate_lold" href="#riskmodels.adequacy.capacity_models.BivariateSequential.simulate_lold">simulate_lold</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential" href="#riskmodels.adequacy.capacity_models.UnivariateSequential">UnivariateSequential</a></code></h4>
<ul class="">
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.Config" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.Config">Config</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.cdf" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.cdf">cdf</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.create_mapred_arglist" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.create_mapred_arglist">create_mapred_arglist</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.demand" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.demand">demand</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.eeu" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.eeu">eeu</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.execute_map" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.execute_map">execute_map</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.gen_dir" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.gen_dir">gen_dir</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.get_surplus_df" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.get_surplus_df">get_surplus_df</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.init" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.init">init</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.lole" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.lole">lole</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.map_reduce" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.map_reduce">map_reduce</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.n_cores" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.n_cores">n_cores</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.renewables" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.renewables">renewables</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.season_length" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.season_length">season_length</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.simulate">simulate</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_eu" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_eu">simulate_eu</a></code></li>
<li><code><a title="riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_lold" href="#riskmodels.adequacy.capacity_models.UnivariateSequential.simulate_lold">simulate_lold</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>